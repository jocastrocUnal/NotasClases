{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f63a48-ce20-45a4-8201-a091dee90573",
   "metadata": {},
   "source": [
    "## Desarrollo Parcial 2 Parte B\n",
    "\n",
    "Inferencia Estadística\n",
    "\n",
    "Profesor Mario Arrieta\n",
    "\n",
    "Presenta: Joan Nicolas Castro Cortes - Estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345817fc-97cb-4581-a737-964077b012fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### **(1)** \n",
    "De los estimadores que normalmente se consideran para la varianza poblaciónal \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "cuando se tiene una muestra aleatoria de una población normal,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58454c0e-d0b5-46ee-9fe9-8b6a8e0bfd97",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "¿Cuál tiene menor varianza?\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Por propiedades de la varianza muestral vimos que si la muestra aleotaria es normal, se tiene que $\\frac{(n-1)S_n^2}{\\sigma^2} \\sim \\chi^2(n-1)$. Donde tenemos que $\\operatorname{var}{( \\frac{(n-1)S_n^2}{\\sigma^2} )} = \\operatorname{Var}{( \\chi^2(n-1) )} = 2(n-1)$. De este modo \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{Var}{(S_n^2)} \n",
    "& = \\operatorname{Var}{\\left( \\frac{\\sigma^2}{(n-1)} \\chi^2(n-1) \\right)} \\\\ \n",
    "& = \\frac{\\sigma^4}{(n-1)^2} \\operatorname{Var}{\\left( \\chi^2(n-1) \\right)} \\\\ \n",
    "& = \\frac{\\sigma^4}{(n-1)^2} 2(n-1) \\\\ \n",
    "& = \\frac{2 \\sigma^4}{n-1} \\\\ \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por otro lado teniendo en cuenta que $S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2$ entonces \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\sigma}^2 \n",
    "& = \\frac{n-1}{n-1}\\frac{1}{n} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2 \\\\\n",
    "& =  \\frac{n-1}{n}\\frac{1}{n-1} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2 \\\\\n",
    "& = \\frac{n-1}{n} S_n^2 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "De este modo tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{Var}{(\\hat{\\sigma}^2)} \n",
    "& = \\operatorname{Var}{\\left( \\frac{n-1}{n}S_n^2 \\right)} \\\\\n",
    "& =  \\frac{(n-1)^2}{n^2}\\operatorname{Var}{\\left(S_n^2 \\right)} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde por el resultado anterior tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{Var}{(\\hat{\\sigma}^2)} \n",
    "& =  \\frac{(n-1)^2}{n^2} \\frac{2 \\sigma^4}{n-1} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Así, teniendo en cuenta que $\\frac{n-1}{n} < 1$ para todo $n \\in \\mathbb{Z}^+$, entonces $\\left( \\frac{n-1}{n} \\right)^2 < 1$ de este modo, dado que la varianza siempre en una cantidad positiva concluimos que $\\frac{(n-1)^2}{n^2} \\frac{2 \\sigma^4}{n-1} < \\frac{2 \\sigma^4}{n-1}$ es decir $\\operatorname{Var}{(\\hat{\\sigma}^2)} < \\operatorname{Var}{(S_n^2)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c000b2-07c9-471d-942e-9c2805196e83",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "¿Cuál tiene menor error cuadrático medio?\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Por propiedades de la varianza muestral tenemos que $E(S_n^2) = \\sigma^2$ de este modo tenemos que el error cuadrático medio de la varianza muestral $S_n^2$ es \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{MSE}{(S_n^2)} \n",
    "& = B^2(S_n^2) + \\operatorname{Var}(S_n^2) \\\\\n",
    "& = [E(S_n^2)-\\sigma^2]^2 + \\operatorname{Var}(S_n^2) \\\\\n",
    "& = [\\sigma^2-\\sigma^2]^2 + \\frac{2 \\sigma^4}{n-1} \\\\\n",
    "& = \\frac{2 \\sigma^4}{n-1} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "es decir el error cuadrático medio de la varianza muestral es $S_n^2$ es un estimador insesgado y por ende ese error cuadrático medio es su misma varianza.\n",
    "\n",
    "Para el estimador $\\hat{\\sigma}^2$ tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(\\hat{\\sigma}^2) \n",
    "& = E\\left( \\frac{1}{n} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2 \\right) \\\\\n",
    "& = E\\left( \\frac{n-1}{n-1} \\frac{1}{n} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2 \\right) \\\\\n",
    "& = E\\left( \\frac{n-1}{n} \\frac{1}{n-1} \\sum_{i=1}^{n} (X-\\bar{X}_n)^2 \\right) \\\\\n",
    "& = E\\left( \\frac{n-1}{n} S_n^2 \\right) \\\\\n",
    "& = \\frac{n-1}{n} E\\left( S_n^2 \\right) \\\\\n",
    "& = \\frac{n-1}{n} \\sigma^2 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Luego el error cuadrático medio del estimador $\\hat{\\sigma}^2$ es\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{MSE}{(\\hat{\\sigma}^2)}\n",
    "& = B^2(\\hat{\\sigma}^2) + \\operatorname{Var}(\\hat{\\sigma}^2) \\\\\n",
    "& = \\left[ E(\\hat{\\sigma}^2)-\\sigma^2 \\right]^2 + \\operatorname{Var}(\\hat{\\sigma}^2) \\\\\n",
    "& = \\left[ \\frac{n-1}{n} \\sigma^2 -\\sigma^2 \\right]^2 + \\frac{(n-1)^2}{n^2} \\frac{2 \\sigma^4}{n-1} \\\\\n",
    "& = \\left[ \\frac{n-1}{n} \\sigma^2 -\\sigma^2 \\right]^2 + \\frac{n-1}{n^2} \\frac{2 \\sigma^4}{1} \\\\\n",
    "& = \\left[ \\frac{-\\sigma^2}{n} \\right]^2 + \\frac{2(n-1)\\sigma^4}{n^2} \\\\\n",
    "& = \\frac{\\sigma^4}{n^2} + \\frac{2(n-1)\\sigma^4}{n^2} \\\\\n",
    "& = \\frac{\\sigma^4 + 2(n-1)\\sigma^4}{n^2} \\\\\n",
    "& = \\frac{\\sigma^4[1 + 2(n-1)]}{n^2} \\\\\n",
    "& = \\frac{\\sigma^4[1+2n-2]}{n^2} \\\\\n",
    "& = \\frac{\\sigma^4[2n-1]}{n^2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por lo tanto, haciendo uso de la eficiencia relativa, para comparar los estimadores, tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "RE(\\hat{\\sigma}^2,S_n^2)\n",
    "= & \\frac{\\operatorname{MSE}(\\hat{\\sigma}^2)}{\\operatorname{MSE}(S_n^2)} \\\\\n",
    "= & \\frac{ \\frac{\\sigma^4[2n-1]}{n^2} }{ \\frac{2 \\sigma^4}{n-1} } \\\\\n",
    "= &  \\frac{(n-1)[2n-1] }{ 2 n^2 } \\\\\n",
    "= &  \\frac{ 2n^2 -n -2n +1 }{ 2 n^2 } \\\\\n",
    "= &  \\frac{ 2n^2 -3n +1 }{ 2 n^2 } \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Donde teneiendo en cuenta que $n\\in \\mathbb{Z}^+$ concluimos que incluso para una muestra aleatoria de desde $n=2$ en adelante ($n=1$ no está definida), el valor de $\\frac{ 2n^2 -3n +1 }{ 2 n^2 } < 1$ y por lo tanto tenemos que $\\hat{\\sigma}^2$ es más eficiente que $S_n^2$, lo cual equivale a decir que $\\operatorname{MSE}(\\hat{\\sigma}^2) <  \\operatorname{MSE}(S_n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48aa239-5607-4276-947f-9007e056bd26",
   "metadata": {},
   "source": [
    "---\n",
    "### **(2)** \n",
    "Si $X_1,X_2,\\cdots,X_n$ es una muestra aleatoria de una población con función de densidad\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_{X}(x, \\theta)=\\frac{2 x}{\\theta^{2}} I_{(0, \\theta]}(x) \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde $\\theta>0$. \n",
    "\n",
    "Primero notemos que para tener una función de densidad $f_{X}(x) = \\frac{2 x}{\\theta^{2}} I_{(0, \\theta]}(x) \\geq 0$, luego $x\\geq 0$. Ahora $\\int_{-\\infty}^{\\infty} f_{X}(x) dx = \\int_{0}^{\\infty}\\frac{2 x}{\\theta^{2}} I_{(0, \\theta]}(x)dx =\\int_{0}^{\\theta} \\frac{2 x}{\\theta^{2}}dx =  1$. Luego tenemos una función de densidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b02b4-616d-4e57-a07f-357e1219ddc4",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Encuentre el MLE de $\\theta$\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Para encontrar el MLE del parámetro $\\theta$ de la distribución $f_X$ de las variables aleatorias veamos que la verosimilitud nos deja que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta | x) \n",
    "& \\overset{\\text{m.a.}}{=} \\prod_{i=1}^{n} f_{X}(x_i, \\theta) \\\\\n",
    "& = \\prod_{i=1}^{n} \\frac{2 x_i}{\\theta^{2}} I_{(0, \\theta]}(x_i) \\\\\n",
    "& = \\frac{2^n \\prod_{i=1}^{n}x_i}{(\\theta^{2})^n}  \\prod_{i=1}^{n} I_{(0, \\theta]}(x_i) \\\\\n",
    "& = \\begin{cases}\n",
    "    \\frac{2^n \\prod_{i=1}^{n}x_i^n}{\\theta^{2n}} & \\text{si } 0 < x_1,x_2,\\cdots,x_n \\leq \\theta \\\\\n",
    "    0 & \\text{e.o.c.} \\\\\n",
    "\\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Donde estamos diciendo que $\\prod_{i=1}^{n} I_{(0, \\theta]}(x_i) = 1$ siempre que $0 < x_1,x_2,\\cdots,x_n \\leq \\theta$ para todo $i \\in \\{ 1,2,\\cdots,n \\}$. Como sólo en la segunda desigualdad tenemos infomación sobre $\\theta$ vemos que $\\theta \\geq X^{(n)}$. De este modo podemos reformular una nueva indicadora que no tenga una restricción con el parámetro la cual es $I_{[X^{(n)},\\infty)}$. Así la verosimilitud está definida de la siguiente manera\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta | x)\n",
    "& = \\frac{2^n \\prod_{i=1}^{n}x_i}{\\theta^{2n}}   \\prod_{i=1}^{n}I_{[X^{(n)},\\infty)} \\\\\n",
    "& = \\begin{cases}\n",
    "    \\frac{2^n \\prod_{i=1}^{n}x_i}{\\theta^{2n}}  & \\text{si } \\theta \\geq X^{(n)} \\\\\n",
    "    0 & \\text{si } \\theta < X^{(n)} \\\\\n",
    "\\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "De este modo, en el intervalo $X^{(n)} \\leq \\theta < \\infty$, la verosimilitud es una función monótona decreciente. Luego tenemos que $\\underset{\\theta > 0}{\\operatorname{arg max}} L(\\theta | x) = X^{(n)}$ y por lo tanto $\\hat{\\theta}_{\\text{MLE}} = X^{(n)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce8945-6740-489a-8500-7e2643d00944",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Encuentre una constante $c$ tal que $E[c \\hat{\\theta}_{\\text{MLE}}] = \\theta$\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Dado que la distribución de $X^{(n)}$ está dada por \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "F_{X^{(n)}} \n",
    "& = \\sum_{j=n}^{n} \\binom{n}{j} \\left[ F_{X}(x) \\right]^j \\left[ 1-F_{X}(x) \\right]^{n-j} \\\\\n",
    "& = \\binom{n}{n}\\left[ F_{X}(x) \\right]^n \\left[ 1-F_{X}(x) \\right]^{0} \\\\\n",
    "& = F_{X}^n(x) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde teniendo en cuenta que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "F_{X}(x) \n",
    "& = \\int_{-\\infty}^{x} f_X(u) du \\\\\n",
    "& = \\int_{0}^{x} f_X(u) du \\quad \\text{(dado que tiene $f_X(x) \\geq 0$)}\\\\\n",
    "& = \\int_{0}^{x} \\frac{2 u}{\\theta^{2}} du \\\\\n",
    "& = \\frac{1}{\\theta^2} \\int_{0}^{x} 2u du \\\\\n",
    "& = \\frac{1}{\\theta^2} [u^2]_{0}^{x} \\\\\n",
    "& = \\frac{x^2}{\\theta^2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "entonces \n",
    "\n",
    "$$F_{X^n}(x) = \\frac{x^{2n}}{\\theta^{2n}}$$\n",
    "\n",
    "y así\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_{X^{(n)}}\n",
    "& = \\frac{d}{dx} F_X^n(x) \\\\\n",
    "& = \\frac{d}{dx} \\frac{x^{2n}}{\\theta^{2n}} \\\\\n",
    "& = \\frac{1}{\\theta^{2n}}\\frac{d}{dx} x^{2n} \\\\\n",
    "& = \\frac{1}{\\theta^{2n}}(2n)x^{2n-1} \\\\\n",
    "& = \\frac{2n}{\\theta^{2n}}x^{2n-1} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "con $\\theta > 0$ y $0 < x < \\theta$ . Por lo tanto \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(\\hat{\\theta}_{\\text{MLE}})\n",
    "& = \\int_{0}^{\\theta} x f_{X^{(n)}}(x) dx \\\\\n",
    "& = \\int_{0}^{\\theta} x \\frac{2n}{\\theta^{2n}}x^{2n-1} dx \\\\\n",
    "& =  \\frac{2n}{\\theta^{2n}} \\int_{0}^{\\theta} xx^{2n-1} dx \\\\\n",
    "& =  \\frac{2n}{\\theta^{2n}} \\int_{0}^{\\theta} x^{2n} dx \\\\\n",
    "& =  \\frac{2n}{\\theta^{2n}} \\left[ \\frac{x^{2n+1}}{2n+1} \\right]_{0}^{\\theta} \\\\\n",
    "& =  \\frac{2n}{\\theta^{2n}} \\frac{\\theta^{2n+1}}{2n+1} \\\\\n",
    "& =  \\frac{2n}{2n+1} \\theta \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde así $c=\\frac{2n+1}{2n}$ dado que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(c\\hat{\\theta}_{\\text{MLE}}) \n",
    "& = E(\\frac{2n+1}{2n}\\hat{\\theta}_{\\text{MLE}}) \\\\\n",
    "& = \\frac{2n+1}{2n} E(\\hat{\\theta}_{\\text{MLE}}) \\\\\n",
    "& = \\frac{2n+1}{2n} \\frac{2n}{2n+1} \\theta \\\\\n",
    "& = \\theta \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298388b6-b9b7-488d-924e-dd79fdbbbef5",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "Encuentre el MLE de la mediana de la distribución. Muestre que dicho estimador es consistente simple\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Teniendo en cuenta la función de distribución de $X$ es $F_X(x) = \\frac{x^2}{\\theta^2}$, cuando nos preguntan por la mediana tenemos que ver que $F_X(x) = \\frac{1}{2}$. Luego $\\frac{x^2}{\\theta^2} = \\frac{1}{2}$ y de este modo tenemos que $x = \\frac{\\theta}{\\sqrt{2}}$. Por el teorema de invarianza del MLE podemos decir que el estimador de la mediana en MLE es $\\hat{M}_e = \\frac{X^{(n)}}{\\sqrt{2}}$. Ahora la definición de consistencia simple que es:\n",
    "\n",
    "> Un estimador $\\hat{\\theta}(\\mathbf{X}_n)$ para el parámetro $\\theta$ se dice consistente simple si:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right) \n",
    "\\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}}\n",
    "\\theta, \\forall \\theta \\in \\Theta\n",
    "$$ \n",
    "\n",
    "luego debemos ver entonces que $\\hat{M}_e \\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}} M_e$. \n",
    "\n",
    "Por propiedades de la convergencia en probabilidad tenemos que $\\sqrt{2} \\hat{M}_e \\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}} \\sqrt{2} M_e$ es decir bastaría ver que $X^{(n)} \\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}} \\theta$. Ahora teniendo en cuenta la definición de convergencia en error cuadrático medio que es\n",
    "\n",
    "> Un estimador $\\hat{\\theta}(\\mathbf{X}_n)$ para el parámetro $\\theta$ se dice consistente en error cuadrático medio si:\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} \\operatorname{MSE}\\left(\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right), \\theta\\right)=0, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "tenemos que \n",
    "\n",
    "> $E(X^{(n)2})= \\int_{0}^{\\theta} x^2 f_{X^{(n)}}(x) =  \\int_{0}^{\\theta} x^2 \\frac{2n}{\\theta^{2n}}x^{2n-1} dx = \\frac{2n}{2n+2}\\theta^2$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\lim_{n\\to\\infty} \\operatorname{MSE}\\left( X^{(n)}, \\theta \\right) \n",
    "& = \\lim_{n\\to\\infty} \\left( B^2(X^{(n)}) + \\operatorname{Var}(X^{(n)}) \\right) \\\\\n",
    "& = \\lim_{n\\to\\infty} \\left( \\left[ E(X^{(n)}) - \\theta \\right]^2 + E(X^{(n)^2}) - [E(X^{(n)})]^2 \\right) \\\\\n",
    "& = \\lim_{n\\to\\infty} \\left( \\left[ \\frac{2n}{2n+1} \\theta - \\theta \\right]^2 + \\frac{2n}{2n+2}\\theta^2 - \\left[ \\frac{2n}{2n+1} \\theta \\right]^2 \\right) \\\\\n",
    "& = \\lim_{n\\to\\infty} \\left( \\left[ \\frac{2n}{2n+1} \\theta - \\theta \\right]^2  \\right) + \\lim_{n\\to\\infty} \\left( \\frac{2n}{2n+2}\\theta^2  \\right) - \\lim_{n\\to\\infty} \\left( \\left[ \\frac{2n}{2n+1} \\theta \\right]^2 \\right) \\\\\n",
    "& = 0 +\\theta^2-\\theta^2 \\\\\n",
    "& = 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Es decir que $X^{(n)}$ es consistente en error cuadrático medio (MSE) a $\\theta$ y dado que al tener la consistencia en error cuadrático medio implica la consistencia simple hemos terminado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca6cc0-12a4-4049-92b7-a7c4ecc864f8",
   "metadata": {},
   "source": [
    "---\n",
    "### **(3)** \n",
    "Si $X_1,X_2,\\cdots,X_n$ es una muestra aleatoria de una población con función de densidad.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_{X}(x, \\theta)=\\left(\\frac{1}{\\theta}\\right)^{2} x e^{-\\left(\\frac{x}{\\theta}\\right)} I_{(0, \\infty)}(x) \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde $\\theta>0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a7f8c-a349-49c9-bd3c-eeef637f1980",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "¿Es $\\sum_{i=1}^{n} X_i$ una estadística suficiente y completa para $\\theta?$\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Primero debemos tener en cuenta que $f_X$ es una función de densidad la cual pertenece a la familia exponencial de densidades, dado que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_{X}(x, \\theta)\n",
    "& =\\left(\\frac{1}{\\theta}\\right)^{2} x e^{-\\left(\\frac{x}{\\theta}\\right)} I_{(0, \\infty)}(x) \\\\\n",
    "& =\\left(\\frac{1}{\\theta}\\right)^{2} xI_{(0, \\infty)}(x)  e^{-\\left(x \\frac{1}{\\theta}\\right)}  \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde teniendo en cuenta que \n",
    "> para $\\mathbf{X}$ un vector aleatorio con función de densidad/masa de probabilidad $f_X / p_X$ parametrizado por $\\theta \\in \\Theta \\subseteq \\mathbb{R}$. Se dice que el modelo probabilístico $f_X/p_X$ pertenece a la ***familia exponencial*** si éste se puede escribir como:\n",
    "$$\n",
    "\\left(f_{\\mathbf{X}}(\\mathbf{x} ; \\theta)=\\right) p_{\\mathbf{x}}(\\mathbf{x} ; \\theta)=a(\\theta) b(\\mathbf{x}) \\exp [c(\\theta) d(\\mathbf{x})] \\forall \\mathbf{x} \\in \\mathbb{R}^{n}, \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "entonces dejando a $a(\\theta) = \\left(\\frac{1}{\\theta}\\right)^{2}$, luego a $b(\\mathbf{x}) = xI_{(0, \\infty)}(x)$ y con $\\exp[c(\\theta) d(\\mathbf{x})] = e^{-\\left(x \\frac{1}{\\theta}\\right)}$ donde $c(\\theta)=\\frac{1}{\\theta}$ y $d(\\mathbf{x})=x$; tenemos que $f$ pertenece a la familia exponencial de densidades.\n",
    "\n",
    "Por lo tanto, teniendo en cuenta el resultado anterior, por teorema se implica que $\\sum_{i=1}^{n} d(X_i)=\\sum_{i=1}^{n} X_i$ es una estadística suficiente y completa para el parámetro $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6803db3-6462-4924-9106-05faa285674d",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Determine un estimador insesgado para $\\theta$ que sea función de $\\sum_{i=1}^{n} X_i$ tal que él tenga la varianza mínima\n",
    "\n",
    "***Solución:***\n",
    "\n",
    "Debemos enconrar un estimador insesgado para $\\theta$ que sea función de estadísticas suficientes y completas de $\\theta$ para asi tener que éste es el estimador con varianza mínima dentro de los estimadores insesgados.\n",
    "\n",
    "Veamos primero que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(X)\n",
    "& = \\int_{-\\infty}^{\\infty} xf_{X}(x, \\theta) dx \\\\\n",
    "& = \\int_{-\\infty}^{\\infty} x\\left(\\frac{1}{\\theta}\\right)^{2} x e^{-\\left(\\frac{x}{\\theta}\\right)} I_{(0, \\infty)}(x) dx \\\\\n",
    "& =  \\int_{0}^{\\infty} \\frac{1}{\\theta^{2}} x^2e^{-\\left(\\frac{x}{\\theta}\\right)} dx \\\\\n",
    "& = 2\\theta \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Así, dado que la función, pertenece a la familia exponencial de densidades, por teorema tenemos que el estimador por MLE de $\\theta$ es\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} d\\left(X_{i}\\right)\\\\\n",
    "E[X]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\\\\n",
    "2\\theta\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\bar{X}_n \\\\\n",
    "2\\hat{\\theta}_{\\text{MLE}} & = \\bar{X}_n \\\\\n",
    "\\hat{\\theta}_{\\text{MLE}} & = \\frac{\\bar{X}_n}{2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Donde por tanto al tener que el estimador por MLE $\\hat{\\theta}_{\\text{MLE}}  = \\frac{\\bar{X}_n}{2}$ que es función de las estadísticas suficientes y completas por el Teorema de Lehman-Sheffé se tiene es este estimador es un UMVUE (Uniformly Minimum-Variance Unbiased Estimator), es decir que es el estimador insesgado de varianza uniformemente mínima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71681e4-fa9c-4d18-a485-06ccd9b892b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
