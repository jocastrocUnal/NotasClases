{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f63a48-ce20-45a4-8201-a091dee90573",
   "metadata": {},
   "source": [
    "## Desarrollo Parcial 1 Parte B\n",
    "\n",
    "Inferencia Estadística\n",
    "\n",
    "Profesor Mario Arrieta\n",
    "\n",
    "Presenta: Joan Nicolas Castro Cortes - Estadística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345817fc-97cb-4581-a737-964077b012fd",
   "metadata": {},
   "source": [
    "---\n",
    "### **(1)**\n",
    "#### **(a)** \n",
    "\n",
    "- **Condición suficiente de diferenciabilidad:** Sea $f:U\\subset \\mathbb{R}^n \\to \\mathbb{R}$ una función de clase $\\mathcal{C}^1$ en un punto $a \\in U$, i.e. que las derivadas parciales de $f$ en una vecindad de $a$ existen y son continuas; entonces $f$ es diferenciable en $a$.\n",
    "\n",
    "- **Condición necesaria de la existencia del $k$-ésimo momento:** Sea $X$ una variable aleatoria. La función característica $\\phi_X$ de $X$ si $E(X^k)$ existe entonces $\\frac{d^k}{dt^k}\\phi_X(t) \\Big|_{t=0} = i^kE(X^k)$\n",
    "\n",
    "Para ver si la función $\\phi_X$ es diferenciable basta ver que su primera derivada existe y esta es continua es los mismos valores que toma de $\\phi_X$. En particular para saber si $\\phi_X$ es diferenciable en $0$ tenemos que ver si su primera derivada existe y esta es continua alrrededor de $0$. Esto se conoce como la condición suficiente de diferenciabilidad.\n",
    "\n",
    "Pero como tenemos que \n",
    "$$\n",
    "\\phi_X'(t)=\\frac{-t e^{-|t|}}{|t|}\n",
    "$$\n",
    "entonces tenemos que $\\phi_X'$ no es continua cuando $t=0$ y por lo tanto **no es diferenciable arrededor de cero**. \n",
    "\n",
    "Teniendo en cuenta que es condición necesaria que la función característica sea diferenciable en $t=0$, almenos una vez, para tener que $E(X)<\\infty$. **Entonces el resultado afirma que una variable aleatoria con distribución cauchy estándar no tiene momentos desde los de primer orden**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900a6b8-5b72-45bf-9666-7b26962d921b",
   "metadata": {},
   "source": [
    "#### **(b)**\n",
    "- **Propiedad del valor esperado** Si $X$ e $Y$ son variables aleatorias independientes entonces $E(XY) = E(X)E(Y)$. Tambien si $g(X)$ y $h(Y)$ son variables aleatorias independientes entonces $E(g(X)h(Y)) = E(g(X))E(h(Y))$.\n",
    "\n",
    "Vamos a utilizar la función característica para verificar que tanto $X_i$ como $\\overline{X}_n$ tienen distribución de Cauchy estándar. Teniendo la definición de función característica entonces\n",
    "$$\n",
    "\\begin{split}\n",
    "\\phi_{\\overline{X}_n} \n",
    "& = E(e^{t\\overline{X}_n}) \\\\\n",
    "& = E(e^{[t\\overline{X}_n]}) \\\\\n",
    "& = E\\left(e^{\\left[t\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right]}\\right) \\\\\n",
    "& = E\\left(e^{ \\frac{t}{n} \\left[ \\sum_{i=1}^{n} X_i\\right]}\\right) \\\\\n",
    "& = E\\left(e^{ \\frac{t}{n} \\left[ X_1 + X_2 + \\cdots + X_n \\right]}\\right) \\\\\n",
    "& = E\\left(e^{ \\frac{t}{n} X_1 + \\frac{t}{n} X_2 + \\cdots + \\frac{t}{n} X_n }\\right) \\\\\n",
    "& = E\\left(e^{ \\frac{t}{n} X_1} e^{\\frac{t}{n} X_2} \\cdots  e^{\\frac{t}{n} X_n }\\right) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "De este modo por propiedades del valor esperado tenemos que \n",
    "$$\n",
    "\\begin{split}\n",
    "\\phi_{\\overline{X}_n} \n",
    "& = E\\left(e^{ \\frac{t}{n} X_1} e^{\\frac{t}{n} X_2} \\cdots  e^{\\frac{t}{n} X_n }\\right) \\\\\n",
    "& = E\\left(e^{ \\frac{t}{n} X_1}\\right) E\\left(e^{\\frac{t}{n} X_2}\\right) \\cdots  E\\left(e^{\\frac{t}{n} X_n }\\right) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "Sea $\\frac{t}{n}=t^*$ entonces\n",
    "$$\n",
    "\\begin{split}\n",
    "\\phi_{\\overline{X}_n} \n",
    "& = E\\left(e^{ t^* X_1}\\right) E\\left(e^{t^* X_2}\\right) \\cdots  E\\left(e^{t^* X_n }\\right) \\\\\n",
    "& = E\\left(e^{-|t^*|}\\right) E\\left(e^{-|t^*|}\\right) \\cdots  E\\left(e^{-|t^*|}\\right) \\\\\n",
    "& = E\\left(e^{n(-|t^*|)}\\right) \\\\\n",
    "& = E\\left(e^{-|nt^*|}\\right) \\\\\n",
    "& = E\\left(e^{-|n\\frac{t}{n}|}\\right) \\\\\n",
    "& = E\\left(e^{-|t|}\\right) \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31e4e5-139e-4d29-9526-d4497a7fbf15",
   "metadata": {},
   "source": [
    "#### **(c)**\n",
    "\n",
    "- **Teorema del límite central (TCL):** Sean $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con media $\\mu$ y varianza $\\sigma^2$ finitas. Y sea $$\\overline{X}_n = \\frac{X_1+X_2+\\cdots+X_n}{n} \\ \\ , \\ \\ \\ T_n=\\sum_{j=1}^{n} X_j$$ Entonces\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{1) } \\frac{T_n-n\\mu}{\\sigma\\sqrt{n}} \\overset{d}{\\underset{n\\to\\infty}{\\longrightarrow}} N(0,1) \n",
    "& \\quad T_n \\approx N(n\\mu , n\\sigma^2) \\\\\n",
    "\\text{2) } \\sqrt{n}\\frac{\\overline{X}_n-\\mu}{\\sigma} \\overset{d}{\\underset{n\\to\\infty}{\\longrightarrow}} N(0,1)\n",
    "& \\quad \\overline{X}_n \\approx N(\\mu,\\frac{\\sigma^2}{n})\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "El teorema del límite central nos dice que es condición necesaria que $\\overline{X}_n  \\overset{d}{\\underset{n\\to\\infty}{\\longrightarrow}} N(\\mu , \\frac{\\sigma^2}{n})$ para tener una muestra aleatoria $X_1, X_2, \\cdots , X_n$ con media $\\mu$ y varianza $\\sigma^2$ finitas. Pero **como tenemos que $\\overline{X}_n \\sim Cauchy(0,1)$ entonces tenemos que en particular $\\overline{X}_n \\overset{d}{\\underset{n\\to\\infty}{\\longrightarrow}} Cauchy(0,1)$, la media muestral de una distribución de cauchy no se ajusta en distribución a una normal de media $\\mu$ y varianza $\\frac{\\sigma^2}{n}$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea8cf03-ce94-4e9a-ba75-7ff5b298fc05",
   "metadata": {},
   "source": [
    "### **(2)**\n",
    "#### **(a)**\n",
    "Nos preguntan por $P(|\\overline{X}_n - \\mu|>2)$ para una muestra aleatoria de $4$ observaciones, donde cada $X_i$ es tal que $X_i \\sim N(\\mu,\\sigma^2) = N(10,10^2)$.\n",
    "\n",
    "Teniendo en cuenta el TCL podemos hacer la siguiente aproximación $\\overline{X}_n \\approx N(\\mu,\\frac{\\sigma^2}{n})$ dado que tenemos que $\\sqrt{n}\\frac{\\overline{X}_n-\\mu}{\\sigma}$. La cual se va haciendo mas precisa a medida que aumenta el número $n$ de observaciones. Para el caso $n=4$ tenemos que \n",
    "$$\n",
    "\\begin{split}\n",
    "P(|\\overline{X}_4 -10| > 2) \n",
    "& = P(\\overline{X}_4 - 10 < -2 \\ \\text{ ó } \\ \\overline{X}_4 - 10 > 2) \\\\\n",
    "& = P(\\overline{X}_4 - 10 < -2 ) +p( \\overline{X}_4 - 10 > 2) \\\\\n",
    "& = P(\\sqrt{4}(\\overline{X}_4 - 10) < \\sqrt{4}(-2) ) +p( \\sqrt{4}(\\overline{X}_4 - 10) > \\sqrt{4}(2) ) \\\\\n",
    "& = P(\\frac{\\sqrt{4}(\\overline{X}_4 - 10)}{10} < \\frac{\\sqrt{4}(-2)}{10} ) +p( \\frac{\\sqrt{4}(\\overline{X}_4 - 10)}{10} > \\frac{\\sqrt{4}(2)}{10} ) \\\\\n",
    "& \\approx \\Phi\\left(\\frac{\\sqrt{4}(-2)}{10}\\right) + \\left( 1 -  \\Phi\\left( \\frac{\\sqrt{4}(2)}{10} \\right)\\right) \\\\\n",
    "& \\approx 0.689\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e94590e-7e39-4e06-8e66-6c7dd3032522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6891565167793516"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import *\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu, sigma2 = 0,1 \n",
    "x=-2/5\n",
    "y=2/5\n",
    "\n",
    "# Evaluación de una funcion de distribución acumulada de una normal estandar loc=0,scale=1\n",
    "a = norm.cdf(x, loc = mu, scale = sigma2) \n",
    "b = norm.cdf(y, loc = mu, scale = sigma2)  \n",
    "a+(1-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74697af3-9026-41b6-94a8-0903e2593bd8",
   "metadata": {},
   "source": [
    "Por lo tanto tenemos que **la probabilidad de que la media muestral diste más de dos unidades de la verdadera media es del 0.689**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ffe2a-17ed-4df8-8481-318228454c46",
   "metadata": {},
   "source": [
    "#### **(b)**\n",
    "Nos preguntan por un $n$ para el cual $P(|\\overline{X}_n - 10| < 0.1) = 0.9$ entonces nuevamente teniendo en cuenta el TCL nuevamente\n",
    "$$\n",
    "\\begin{split}\n",
    "P(|\\overline{X}_n - 10| < 0.1) \n",
    "& = P(-0.1 < \\overline{X}_n - 10 < 0.1) \\\\\n",
    "& = P(\\sqrt{n}(-0.1) < \\sqrt{n}(\\overline{X}_n - 10) < \\sqrt{n}(0.1) ) \\\\\n",
    "& = P\\left(\\frac{\\sqrt{n}(-0.1)}{10} < \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(0.1)}{10} \\right) \\\\\n",
    "& = 1 - P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\ \\text { ó } \\  \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} > \\frac{\\sqrt{n}(0.1)}{10} \\right) \\\\\n",
    "0.9 & = 1 - \\left[ P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right) +  P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} > \\frac{\\sqrt{n}(0.1)}{10} \\right) \\right]\\\\\n",
    "0.9 -1 & = - \\left[ P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right) +  P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} > \\frac{\\sqrt{n}(0.1)}{10} \\right) \\right]\\\\\n",
    "0.1 & =  P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right) +  P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} > \\frac{\\sqrt{n}(0.1)}{10} \\right) \\\\\n",
    "0.1 & = 2P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right)  \\quad \\text{ simetría de de distribución normal estándar} \\\\\n",
    "\\frac{0.1}{2} & = P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right) \\\\\n",
    "0.05 & = P\\left( \\frac{\\sqrt{n}(\\overline{X}_n - 10)}{10} < \\frac{\\sqrt{n}(-0.1)}{10} \\right) \\\\\n",
    "0.05 & = \\Phi\\left(  \\frac{\\sqrt{n}(-0.1)}{10} \\right) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por lo tanto tenemos que encontrar cuantiles de la normal estandar y de este modo tenemos que \n",
    "$$\n",
    "\\begin{split}\n",
    "-1.6448536 & = \\frac{\\sqrt{n}(-0.1)}{10} \\\\\n",
    "-1.6448536\\cdot 10 & = \\sqrt{n}(-0.1) \\\\\n",
    "\\frac{-1.6448536\\cdot 10}{-0.1} & = \\sqrt{n} \\\\\n",
    "\\left( \\frac{1.6448536\\cdot 10}{0.1} \\right)^2 & = n \\\\\n",
    "27056 & \\approx n\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af39e634-165e-4416-8b7d-fbe4b754b917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6448536269514729"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluacion de la mediana en una inversa de una función de distribución acumulada de una normal estandar\n",
    "norm.ppf(0.05, loc =0, scale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf5c43c-177c-4279-846c-01075f228a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27055.433654329594"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1.6448536*10)/0.1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b870a0-85ce-4249-9229-09171d8899de",
   "metadata": {},
   "source": [
    "Entonces **el tamaño de muestra que se requiere para garantizar que la media muestral diste de a lo sumo $0.1$ de la muestra poblacional con una probabilidad de $0.9$ es de $27056$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c867dd-c39f-4354-ad00-0deee1ac0ce1",
   "metadata": {},
   "source": [
    "#### **(c)**\n",
    "Realmente al hacer uso del TCL no hicimos uso del hecho que la distribución de la muestra aleatoria era normal, ya que solamente necesitabamos tener la certeza de que los datos tenían media $\\mu$ y varianza $\\sigma^2$ finitas. Por lo tanto **si la población no es normal tendriamos que tener la certeza de que almenos sabemos que nuestro valor esperado $\\mu$ y varianza $\\sigma^2$ existen** y dado este hecho **los resultados seguirían siendo válidos** en otro caso podriamos ver como en el primer punto que no podemos hacer uso del TCL. Así pues para mencionar que nuestro resultado **debemos acotar que lo hicimos bajo el supuesto que teníamos una muestra aleatoria y que la distribución de los datos permitian la existencia de la esperanza y la varianza**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ffea9-dd76-49a7-adc9-e6da6d2b22da",
   "metadata": {},
   "source": [
    "### **(6)**\n",
    "#### **(a)**\n",
    "Dado que tenemos que la función de densidad de probabilidad para la muestra aleatoria $X_1,X_2,\\dots,X_n$ es \n",
    "$$\n",
    "f_X(x;\\theta) = e^{-(x-\\theta)}I_{(\\theta,\\infty)}(x) = e^{\\theta-x}I_{(\\theta,\\infty)}(x)\n",
    "$$\n",
    "la cual efectivamente es una función de densidad donde el espacio del parámetro es $\\Theta = int(\\Theta) = \\mathbb{R}$ ya que el conjunto de los números reales es un conjunto abierto; veamos que la función verosimilitud de las muestras aleatorias es\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta|\\mathbf{x}) \n",
    "& = f_{\\mathbf{x}}(\\mathbf{x};\\theta) \\\\\n",
    "& = f_{x_1,x_2,\\cdots,x_n}(x_1,x_2,\\cdots,x_n;\\theta) \\\\\n",
    "& = \\prod_{i=1}^{n} e^{\\theta - x_i} I_{(\\theta,\\infty)}(x_i) \\\\\n",
    "& = e^{\\theta - \\sum_{i=1}^{n} x_i}\\prod_{i=1}^{n}I_{(\\theta,\\infty)}(x_i) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "Es decir que $L(\\theta,\\mathbf{x})=e^{\\theta - \\sum_{i=1}^{n} x_i}$ siempre y cuando $x_i \\in (\\theta,\\infty)$ para toda $i \\in \\{ 1,2,\\cdots,n \\}$. Teniendo en cuenta que nuestro parámetro se encuentra en la condición para que la función de desidad conjunta de valores diferentes a cero no pudemos usar métodos de maximización derivadas del cálculo.\n",
    "\n",
    "Haciendo una aproximación diferente veamos que $\\theta < x_1,x_2, \\cdots, x_n < \\infty$ de este modo tenemos unicamente que $\\theta < x_1,x_2,\\cdots,x_n$. Ahora teniendo en cuenta la definición de estadísticas de orden tenemos que $\\theta < X^{(1)}$. Entonces la función de verosimilitud ahora está definida de la siguiente manera\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta|\\mathbf{x})\n",
    "& =  e^{n\\theta - \\sum_{i=1}^{n} x_i}I_{(X^{(1)},\\infty)}(x_i) \\\\\n",
    "& =  \\begin{cases}\n",
    "         e^{n\\theta - \\sum_{i=1}^{n} x_i} & \\text{Si } \\theta < X^{(1)} \\\\\n",
    "         0 & \\text{Si } \\theta \\geq X^{(1)} \\\\\n",
    "     \\end{cases} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "Por lo tanto notemos que en la función de verosimilitud a medida que el valor de $\\theta$ aumenta $e^{ n \\theta - \\sum x_i}=\\frac{e^{n\\theta}}{\\sum x_i} = \\frac{ e^{n\\theta} }{t} $ tambien aumenta de valor, pero sujeto a la restricción que $\\theta < X^{(1)}$. Lo que es igual a que $e^{n\\theta}$ aumenta de valor a medida que $\\theta$ aumenta pero sujeto a la restricción que $\\theta < X^{(1)}$. \n",
    "\n",
    "De este modo dado que no podemos decir que $\\theta^* = X^{(1)}$ pero si sabemos que a medida que $\\theta \\to X^{(1)}$ la función de verosimilitud se maximiza nuestro criterio de maximización es ahora $\\underset{\\theta \\in \\mathbb{R}}{\\operatorname{sup arg}L(\\theta|\\mathbf{x})}$ es decir la mínima de la cotas superiores de $L$. Y de este modo **tenemos que el estimador por ML es $\\hat{\\theta}_{MLE} = X^{(1)}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0590d8b-6699-4739-a7e4-d2dc69e86e49",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **(b)**\n",
    "Para encontrar el estimador por el método de los momentos veamos que \n",
    "$$\n",
    "\\begin{split}\n",
    "\\mu_1=E(X^1)=E(X)\n",
    "& = \\int_{-\\infty}^{\\infty} x e^{-(x-\\theta)} dx \\\\\n",
    "& = \\int_{\\theta}^{\\infty} x e^{-(x-\\theta)} dx \\\\\n",
    "& = \\int_{\\theta}^{\\infty} (x-\\theta + \\theta) e^{-(x-\\theta)} dx \\\\\n",
    "& = \\int_{0}^{\\infty} (t + \\theta) e^{-t} dt \\\\\n",
    "& = \\int_{0}^{\\infty} (t + \\theta) e^{-t} dt \\\\\n",
    "& = -(t + \\theta + 1) e^{-t} \\big|_0^{\\infty} \\\\\n",
    "& = \\theta + 1 \\\\ \n",
    "\\end{split}\n",
    "$$\n",
    "y teniendo en cuenta que \n",
    "$$\n",
    "\\overset{\\sim}{\\mu}_1 = \\frac{1}{n}\\sum_{i=1}^{n} = \\overline{X}_n\n",
    "$$\n",
    "entonces \n",
    "$$\n",
    "\\begin{split}\n",
    "\\mu_1(\\hat{\\theta}) & = \\overset{\\sim}{\\mu}_1 \\\\\n",
    "\\hat{\\theta} + 1 & = \\overline{X}_n \\\\\n",
    "\\hat{\\theta} & = \\overline{X}_n -1 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "Por lo tanto **el estimador pora el método de los momento para $\\theta$ es $\\hat{\\theta}_{mom} = \\overline{X}_n -1$**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
