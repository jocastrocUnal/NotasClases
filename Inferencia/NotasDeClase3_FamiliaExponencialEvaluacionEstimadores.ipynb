{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61dde4ce-08b8-4521-9b3c-08c7ddbda0ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Familia exponencial de densidades**\n",
    "La famila exponencial de densidades es un conjunto de modelos probabilísticos discretos o continuos los cuales al poderlos asociar a algún otro modelo en particular, este podria simplificar muchos cálculos. Dentro de estos modelos, por ejemplo, se encuentra la densidad exponencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1e9fd-0b7c-420b-b933-3031ece54bb9",
   "metadata": {},
   "source": [
    "### **Familia exponencial uniparamétrica**\n",
    "Sea $\\mathbf{X}$ un vector aleatorio con función de densidad/masa de probabilidad $f_X / p_X$ parametrizado por $\\theta \\in \\Theta \\subseteq \\mathbb{R}$. Se dice que el modelo probabilístico $f_X/p_X$ pertenece a la ***familia exponencial*** si éste se puede escribir como:\n",
    "$$\n",
    "\\left(f_{\\mathbf{X}}(\\mathbf{x} ; \\theta)=\\right) p_{\\mathbf{x}}(\\mathbf{x} ; \\theta)=a(\\theta) b(\\mathbf{x}) \\exp [c(\\theta) d(\\mathbf{x})] \\forall \\mathbf{x} \\in \\mathbb{R}^{n}, \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "> Es decir que el valor de $\\theta$ no tiene que depender de $\\mathbf{x}$ y viseversa.\n",
    "\n",
    "### **Familia exponencial multiparamétrica**\n",
    "Sea $\\mathbf{X}$ un vector aleatorio con función de densidad/masa de probabilidad $f_X / p_X$ parametrizado por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$. Se dice que el modelo probabilístico $f_X/p_X$ pertenece a la ***familia exponencial de densidades*** si éste se puede escribir como:\n",
    "$$\n",
    "\\left(f_{\\mathbf{X}}(\\mathbf{x} ; \\vec{\\theta})=\\right) p_{\\mathbf{x}}(\\mathbf{x} ; \\vec{\\theta})=a(\\vec{\\theta}) b(\\mathbf{x}) \\exp [c(\\vec{\\theta})^T d(\\mathbf{x})] \\forall \\mathbf{x} \\in \\mathbb{R}^{n}, \\vec{\\theta} \\in \\Theta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a544206-a11f-4188-ad92-9cd566197f4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ejemplo \n",
    "Sea $X \\sim P(\\theta)$. Para determinar si este modelo es de la familia exponencial veamos que la función de masa de probabilidad es \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p_X(x;\\theta) \n",
    "& = \\frac{\\theta^x e^{-\\theta}}{x!}  \\\\\n",
    "& = \\theta^x \\frac{1}{x!} e^{-\\theta } I_{0,1,2,\\cdots}(x) \\\\\n",
    "& = e^{\\ln{\\theta^x}} \\frac{1}{x!} e^{-\\theta } I_{\\{0,1,2,\\cdots\\}}(x) \\\\\n",
    "& = e^{\\ln{\\theta^x}} \\frac{1}{x!} e^{-\\theta } I_{\\{0,1,2,\\cdots\\}}(x) \\\\\n",
    "& = e^{-\\theta } \\frac{ I_{\\{0,1,2,\\cdots\\}}(x) }{x!} e^{x\\ln{\\theta}}  \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y de este modo tenemos que $a(\\theta) = e^{-\\theta}$ , $b(x) = \\frac{ I_{\\{0,1,2,\\cdots\\}}(x) }{x!}$ y $c(\\theta)=\\ln{\\theta}$ , $d(\\mathbf{x})=x$ donde nos queda que $\\exp[c(\\theta)d(\\mathbf{x})] = e^{x\\ln{\\theta}}$. Por lo tanto la variable aleatoria $X$ pertenece a la familia exponencial antes definida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b0dab4-b573-4af4-8f11-7d6716611c08",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "Sea $X \\sim Bin(m,\\theta)$, donde $m$ es conocido. Para determianr si este modelo es de la familia explonencial veamos como es la función de masa de probabilidad de una distribución binomial con parámetro $m$ conocido\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x,m;\\theta) \n",
    "& = \\binom{m}{x} \\theta^{x} (1-\\theta)^{m-x} I_{\\{0,1,2,\\cdots,m\\}}(x) \\\\\n",
    "& = \\binom{m}{x} \\theta^{x} \\frac{ (1-\\theta)^{m} }{(1-\\theta)^{x}} I_{\\{0,1,2,\\cdots,m\\}}(x) \\\\\n",
    "& = \\binom{m}{x} \\frac{\\theta^{x}}{(1-\\theta)^{x}}  (1-\\theta)^{m}  I_{\\{0,1,2,\\cdots,m\\}}(x) \\\\\n",
    "& = \\binom{m}{x} \\left( \\frac{\\theta}{(1-\\theta)} \\right)^x (1-\\theta)^{m}  I_{\\{0,1,2,\\cdots,m\\}}(x) \\\\\n",
    "& = (1-\\theta)^{m} \\binom{m}{x}(I_{\\{0,1,2,\\cdots,m\\}}(x)) \\left( \\frac{\\theta}{(1-\\theta)} \\right)^x    \\\\\n",
    "& = (1-\\theta)^{m} \\binom{m}{x}(I_{\\{0,1,2,\\cdots,m\\}}(x)) e^{\\ln {\\left( \\frac{\\theta}{(1-\\theta)} \\right)^x} }    \\\\\n",
    "& = (1-\\theta)^{m} \\binom{m}{x}(I_{\\{0,1,2,\\cdots,m\\}}(x)) e^{x \\ln {\\left( \\frac{\\theta}{(1-\\theta)} \\right)} }    \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y de este modo tenemos que $a(\\theta) = (1-\\theta)^{m}$ , $b(x) = \\binom{m}{x}(I_{\\{0,1,2,\\cdots,m\\}}(x))$ y $c(\\theta)= \\ln {\\left( \\frac{\\theta}{(1-\\theta)} \\right)}$ , $d(\\mathbf{x})=x$ donde nos queda que $\\exp[c(\\theta)d(\\mathbf{x})] = e^{x \\ln {\\left( \\frac{\\theta}{(1-\\theta)} \\right)} }$. Por lo tanto la variable aleatoria $X$ pertenece a la familia exponencial antes definida.\n",
    "\n",
    "> Notemos que al dejar el $m$ conocido tuvimos la oportunidad de encontrar que una variable aleatoria con distribución binomial con ese paramétro como constante pertenece a  la familia explonencial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290d6dd-5cde-4fc2-bac0-f3cb49543ea1",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Sea $X \\sim N(\\mu,\\sigma^2)$ Teniendo como $\\vec{\\theta} = (\\mu,\\sigma^2)^T$ veamos la función de densidad de una variable aleatoria que tienen distribución normal\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(x,\\vec{\\theta}) \n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^{2} \\right]} \\\\\n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{ \\left( x-\\mu \\right)^{2} }{2\\sigma^2} \\right]} \\\\\n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ \\frac{-1}{2\\sigma^2} \\left( x-\\mu \\right)^{2}  \\right]} \\\\\n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ \\frac{-x^2}{2\\sigma^2} + \\frac{2x\\mu}{2\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2} \\right]} \\\\\n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{\\mu^2}{2\\sigma^2} \\right]}    \\exp{\\left[ \\frac{-x^2}{2\\sigma^2} + \\frac{2x\\mu}{2\\sigma^2} \\right]} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "notemos entonces que \n",
    "$$a(\\vec{\\theta})=  \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{\\mu^2}{2\\sigma^2} \\right]} \n",
    "$$\n",
    "y $$b(\\mathbf{x})=1$$ y como $c(\\vec{\\theta}) = (\\frac{-1}{2\\sigma^2} , \\frac{\\mu}{\\sigma^2} )^T$ , $d(\\mathbf{x}) = (x^2 , x)^T$ son tales que\n",
    "$$\\exp[c(\\vec{\\theta})^T d(\\mathbf{x})] =  \\exp{\\left[ \\frac{-x^2}{2\\sigma^2} + \\frac{2x\\mu}{2\\sigma^2} \\right]}$$\n",
    "entonces la variable aleatoria $X$ pertenece a la familia exponencial de densidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e2ed1-cfdd-475f-96c1-0224e36244d6",
   "metadata": {},
   "source": [
    "### **Teorema MLE en la familia exponencial**\n",
    "Sea $X_1, X_2, \\cdots, X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_{\\mathbf{X}}/P_{\\mathbf{X}}$ parametrizado por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$-\n",
    "\n",
    "1. La función de verosimilitud para $\\vec{\\theta}$ viene dada por \n",
    "\n",
    "$$\n",
    "L\\left(\\theta \\mid x_{1}, x_{2}, \\ldots, x_{n}\\right)=a^{n}(\\vec{\\theta})\\left(\\prod_{i=1}^{n} b\\left(x_{i}\\right)\\right) \\exp \\left[\\mathbf{c}(\\vec{\\theta})^{T} \\sum_{i=1}^{n} \\mathbf{d}\\left(x_{i}\\right)\\right]\n",
    "$$\n",
    "\n",
    "2. Además, el MLE para $\\vec{\\theta}$ puede encontrarse resolviendo el sistema de $q$ ecuaciones:\n",
    "\n",
    "$$\n",
    "E\\left[d_{j}(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}}=\\frac{1}{n} \\sum_{i=1}^{n} d_{j}\\left(X_{i}\\right), j=1,2, \\ldots, q\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{d}(\\cdot)=\\left(d_{1}(\\cdot), d_{2}(\\cdot), \\ldots, d_{j}(\\cdot), \\ldots, d_{q}(\\cdot)\\right)^{T}$; siempre que $\\mathbf{c}( \\vec{\\hat{\\theta}}_{MLE}) \\in \\operatorname{int}\\{ \\mathbf{c}(\\vec{\\theta} | \\vec{\\theta} \\in \\Theta)\\}$.\n",
    "\n",
    "3. Si se requiere, $E[d_j(X)]$ puede calcularse como:\n",
    "$$\n",
    "E\\left[d_{j}(X)\\right]=\\frac{\\partial[-\\ln (a(\\vec{\\theta}))]}{\\partial\\left[c_{j}(\\vec{\\theta})\\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d538d31-af42-45ac-b7ee-01fa8499f0b0",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Sea $X \\sim P(\\theta)$. Para determinar el MLE de $\\theta$ a partir de un muestra aleatoria $X_1,X_2, \\cdots, X_n$ entonces dado que sabemos en los ejemplos anteriores que la variable aletoria $X$ pertenece a las familias exponenciales tenemos por el teorema de MLE de familias exponenciales que:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} d\\left(X_{i}\\right)\\\\\n",
    "E[X]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\\\\n",
    "\\theta\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\overline{X}_n \\\\\n",
    "\\hat{\\theta} & = \\overline{X}_n \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "dado que $d(\\mathbf{x})=x$. Tengamos en cuenta tambien que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(d(X)) \n",
    "& = \\frac{\\partial[-\\ln (a(\\vec{\\theta}))]}{\\partial\\left[c_{j}(\\vec{\\theta})\\right]} \\\\\n",
    "& = \\frac{\\partial[-\\ln (e^{-\\theta})]}{\\partial\\left[\\ln \\theta \\right]} \\\\\n",
    "& = \\frac{\\partial[\\theta]}{\\partial\\left[\\ln \\theta \\right]} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde tenemos que $u=\\ln\\theta \\iff \\theta = e^u$ y por tanto \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(d(X)) \n",
    "& = \\frac{\\partial[\\theta]}{\\partial\\left[\\ln \\theta \\right]} \\\\\n",
    "& = \\frac{\\partial[e^u]}{\\partial\\left[u\\right]} \\\\\n",
    "& = e^u \\\\\n",
    "& = \\theta \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f5b60-3b44-41ab-9aa4-61ab448ebc74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ejemplo \n",
    "Sea $X \\sim Bin(m,\\theta)$. Para determinar el MLE de $\\theta$ entonces nuevamente haciendo uso del teorema MLE para familias exponenciales tenemos que:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} d\\left(X_{i}\\right)\\\\\n",
    "E[X]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\\\\n",
    "m\\theta\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\overline{X}_n \\\\\n",
    "m\\hat{\\theta} & = \\overline{X}_n \\\\\n",
    "\\hat{\\theta} & = \\frac{\\overline{X}_n}{m} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "dado que $d(x) = x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e23ff-b6ed-476c-9651-c820e927389b",
   "metadata": {},
   "source": [
    "<a id='EjemploFamiliaExponencialExponencial'></a>\n",
    "### Ejemplo\n",
    "Sea $X \\sim Exp(\\theta)$. Para determinar el MLE de $\\theta$ a partir de una muestra aleatoria $X_1, X_2, \\dots, X_n$ tengamos en cuenta que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(x;\\theta) \n",
    "& = \\theta e^{-\\theta x } I_{(0,\\infty)}(x) \\\\\n",
    "& = \\theta I_{(0,\\infty)}(x) e^{-\\theta x } \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Entonces tenemos que $a(\\theta)=\\theta$ , $b(\\mathbf{x})=I_{(0,\\infty)}(x)$ y como $c(\\theta)=-\\theta$ , $d(\\mathbf{x})=x$ tenemos que $\\exp[c(\\theta)d(\\mathbf{x})] = e^{-\\theta x }$. De este modo tenemos \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} d\\left(X_{i}\\right)\\\\\n",
    "E[X]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\\\\n",
    "\\frac{1}{\\theta}\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} & = \\overline{X}_n \\\\\n",
    "\\frac{1}{\\hat{\\theta}} & = \\overline{X}_n \\\\\n",
    "\\hat{\\theta} & = \\frac{1}{\\overline{X}_n} \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a08b20-cec0-484f-a34f-daf664e99c85",
   "metadata": {},
   "source": [
    "<a id='EjemploMLEExponencialNormal'></a>\n",
    "### Ejemplo\n",
    "Sea $X \\sim N(\\mu,\\sigma^2)$\n",
    "\n",
    "1.  Vamos a determinar MLE de $\\theta = (\\mu , \\sigma)^T$ a partir de una muestra aleatoria $X_1,X_2,\\cdots, X_n$ sin hacer uso del teorema anterior.\n",
    "\n",
    "Primero tengamos en cuenta que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\mathbf{x}|\\vec{\\theta}) \n",
    "& = \\prod_{i=1}^{n} f_X(x;\\vec{\\theta}) \\\\\n",
    "& = \\prod_{i=1}^{n} \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left[ \\frac{-(x_i-\\mu)^2}{2\\sigma^2} \\right] \\\\\n",
    "& = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\prod_{i=1}^{n} \\exp\\left[ \\frac{-(x_i-\\mu)^2}{2\\sigma^2} \\right] \\\\\n",
    "& = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\exp\\left[ \\sum_{i=1}^{n} \\frac{-(x_i-\\mu)^2}{2\\sigma^2} \\right] \\\\\n",
    "L(\\mathbf{x}|\\vec{\\theta}) & = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2\\right] \\\\\n",
    "l(\\mathbf{x}|\\vec{\\theta}) & = \\ln \\left(\\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2\\right] \\right) \\\\\n",
    "l(\\mathbf{x}|\\vec{\\theta}) & = \\ln \\left(\\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\right) + \\ln \\left( \\exp\\left[ \\frac{-1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2\\right] \\right) \\\\\n",
    "l(\\mathbf{x}|\\vec{\\theta}) & = \\ln(1) -n\\ln(\\sigma)  -\\frac{n}{2}\\ln(2\\pi) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2 \\\\\n",
    "l(\\mathbf{x}|\\vec{\\theta}) & = -\\frac{n}{2}\\ln(\\sigma^2)  -\\frac{n}{2}\\ln(2\\pi) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "De este modo para encontrar los puntos estacionarios de $l$ tenemos \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\nabla l(\\mathbf{x}|\\vec{\\theta})  \n",
    "& = \\left( \\frac{\\partial l }{\\partial \\mu} , \\frac{\\partial l }{\\partial \\sigma^2} \\right) \\\\\\mathbf{x}|\\vec{\\theta} \\\\\n",
    "& =  \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "***(desarrollo 20211115 45:00)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb2a47-9c7c-40ae-a871-e85e15a3a516",
   "metadata": {},
   "source": [
    "2. Ahora haciendo uso del teorema para estima MLE tenemos, por un lado\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d_1(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} \n",
    "& = E\\left[x^{2}\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} \\\\\n",
    "& =\\hat{\\mu}^{2}+\\hat{\\sigma}^{2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y tambien \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{1}{n} \\sum_{i=1}^n d_1(X_i) = \\frac{1}{n} \\sum_{i=1}^n \n",
    "X_i^2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "luego \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\mu}^{2}+\\hat{\\sigma}^{2} & = \\frac{1}{n} \\sum_{i=1}^n X_i^2 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "por otro lado \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[d_2(X)\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} \n",
    "& = E\\left[x\\right]\\Big|_{\\vec{\\theta}=\\vec{\\hat{\\theta}}_{MLE}} \\\\\n",
    "& =\\hat{\\mu} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y tambien \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{1}{n} \\sum_{i=1}^n d_2(X_i) = \\frac{1}{n} \\sum_{i=1}^n \n",
    "X_i \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "luego \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\mu} & = \\frac{1}{n} \\sum_{i=1}^n X_i\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "de este modo tenemos que $\\hat{\\mu}_{MLE} = \\overline{X}_n$. Aplicando este resultado en la primera ecuación tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\mu}^{2}+\\hat{\\sigma}^{2} & = \\frac{1}{n} \\sum_{i=1}^n X_i^2 \\\\\n",
    "\\overline{X}_n^2+\\hat{\\sigma}^{2} & = \\frac{1}{n} \\sum_{i=1}^n X_i^2 \\\\\n",
    "\\hat{\\sigma}^{2} & = \\frac{1}{n} \\sum_{i=1}^n X_i^2 - \\overline{X}_n^2\\\\ \n",
    "\\hat{\\sigma}^{2} & = \\frac{1}{n} \\sum_{i=1}^n ( X_i - \\overline{X}_n)^2\\\\ \n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "entonces $\\hat{\\sigma}^2_{MLE} =  \\frac{1}{n} \\sum_{i=1}^n ( X_i - \\overline{X}_n)^2$.\n",
    "\n",
    "> Notemos que este resultado tambien lo obtuvimos cuando estimamos los parámetros de una muestra aleatoria cuya distribución es normal por el método de los momentos. Esta coincidencia se puede seguir notando si nuestros dado nuestro teorema obtenemos los valores para $d_i(.)$ correspondientes. Tambien notemos que al coincidir los estimadores por los primeros momentos y por maximo verosimilitud, estos momentos son entonces los que nos aportan más información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f038e9-0aff-4ca0-87ce-593452559fc4",
   "metadata": {},
   "source": [
    "![link](enfoqueEstimacion.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb978a89-5805-4f5c-a5ab-1625c9992295",
   "metadata": {},
   "source": [
    "## **Introducción a la teoría de la decisión**\n",
    "Recordando que un estimador es una variable aleatoria, la cual es una estadística asociado a un parámetro sobre una distribución, donde tenemos que la estimación es una realización del estimador. De este modo con los métodos de estimación pretendiamos encontrar estimadores, ahora vamos a evaluarlar su validez. Podriamos ver entonces que la precisión del estimador va en relación con la varianza (ojalá se concetre en algún valor y ojalá cercano a $\\theta$) y la exactitud del estimador tiene que ver con el valor esperado del estimador (ojalá el valor esperdo sea $\\theta$).\n",
    "\n",
    "Dependiendo de las carácteristicas de viabilidad de los múltiples problemas a los que nos podemos enfretar la decisión de cual estimador es el que mejor se asocia a nuestra población sera un tema de sumo cuidado para poder dar las garantias de que no se toman decisiones a ligera. Veamos por un momento que nuestras desiciones pueden basarse .\n",
    "\n",
    "Puede que esta metodología sea un poco subjetiva desde el punto de vista donde se enfoque el problema o desde la perpectiva particular. Pero en cierto modo podemos tomar una desición desde el criterio estadísticico para llegar \"mejor opción\".\n",
    "\n",
    "![](Captura.PNG)\n",
    "\n",
    "Entonces encuanto al criterio de la \"mejor opción\" nos encontramos que tenemos en realidad un problema de optimización. Por ejemplo como minimizar los costos, maximizar la rentabilidad, etc. Luego en estadística tenemos darle un mejor valor al parámetro, reducir la varianza del estimador, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf419b0-7a76-4670-86e2-4173cec0e5c2",
   "metadata": {},
   "source": [
    "### **Función de pérdida**\n",
    "Sea $a=\\theta(\\mathbf{x})$ (estimación) una decisión respecto a $\\theta$ (el parámetro de la población) a la luz de los datos. La función de pérdida es una función no negativa que busca evaluar la cercanía de la decisión al verdadero parámetro de acuerdo con alguna medida de distancia.\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(a,\\theta) & = |a-\\theta|  \\quad \\text{(pérdida en abs)}\\\\\n",
    "L(a,\\theta) & = (a-\\theta)^2 \\quad \\text{(pérdida cuadrática)}\\\\\n",
    "L(a,\\theta) & = \\frac{a}{\\theta} -1 -\\log\\left(\\frac{a}{\\theta}\\right) \\quad \\text{(pérdida Stein)}\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por ejemplo la función de pérdida de Stein penaliza más a los valores que se alejan más del valor esperado, es decir que toma en cuenta más la varianza de los datos. La función de pérdida cuadrática es bastante utiliza en los modelos de aprendizage de máquina y es una de las más utilizadas. Esto es porque es diferenciable y el valor absoluto no. Es importante notar que la elección de la función de pérdida es a criterio dependiendo de la naturalza de los datos. Por ejempo si tenemos que estimar la comida promedio entregada a los niños de la Guajira podriamos ver que la función de pérdida cuadrática y en valor absoluto tienen grandes diferencias.\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/VWErgC8hMW6tAZMv42J4365UcYOv_wZtHyjJVVTv19E.original.fullsize.png)\n",
    "\n",
    "> Notemos que aún tenemos a $\\theta$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645617ba-8b23-452a-9e1a-5cb0e626ae57",
   "metadata": {},
   "source": [
    "### **Función de riesgo**\n",
    "El riesgo de un mecanismo de decisión se entiendo como la pérdida esperada sobre todos los posibles escenarios de decisión del mecanismo.\n",
    "\n",
    "$$\n",
    "R(\\hat{\\theta}, \\theta)=E_{\\theta}[L(\\hat{\\theta}(\\mathbf{X}), \\theta)]\n",
    "$$\n",
    "\n",
    "> Si bien la función de riesgo tiene en cuenta la aleatoriedad del estimador, depende aún del parámetro desconocido. Lo que hace esta función es poner el estimador como variable aleatoria y luego le saca un valor esperado (la L no es de MLE es de función de pérdida), de este modo tenemos la pérdida esperada.\n",
    "\n",
    "- Bajo la función de pérdida cuadrática, la función de riesgo se conoce como **error cuadrático medio:**\n",
    "\n",
    "$$\n",
    "(\\text{Mean Square Error}) \\quad \\operatorname{MSE}(\\hat{\\theta}, \\theta)=E_{\\theta}\\left[(\\hat{\\theta}(\\mathbf{X})-\\theta)^{2}\\right]\n",
    "$$\n",
    "\n",
    "> Notemos que el error cuadrático medio tiene  una forma de varianza para la variable aletoria $\\hat{\\theta}(\\mathbf{X})$ siempre y cuando el valor esperado de nuestro estimador fuera $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cc3fc-1c0a-4dbf-91d8-32054c8b162a",
   "metadata": {},
   "source": [
    "### **Sesgo**\n",
    "El sesgo (\"bias\") de un estimador $\\hat{\\theta}(\\mathbf{X})$ para el parámetro $\\theta$ se define como:\n",
    "\n",
    "$$\n",
    "B_{\\theta}(\\hat{\\theta}(\\mathbf{X})) \\doteq E[\\hat{\\theta}(\\mathbf{X})]-\\theta\n",
    "$$\n",
    "\n",
    "Si el sesgo del estimador es cero, se dice que éste es insesgado (\"unbiased\").\n",
    "\n",
    "> Notemos que el sesgo es la distancia entre el valor esperado de nuestro estimador y el parámetro de la población asiciado a ese estimador. Cuando estos dos son iguales decimos que nuestro estimador es insesgado.\n",
    "\n",
    "#### **Teorema MSE en términos del sesgo y la varianza**\n",
    "Para cualquier estimador $\\hat{\\theta}(\\mathbf{X})$  de $\\theta$, con $E[\\hat{\\theta}(\\mathbf{X})] < \\infty$ tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{MSE}(\\hat{\\theta}, \\theta) \n",
    "& = E_{\\theta}\\left[(\\hat{\\theta}(\\mathbf{X})-\\theta)^{2}\\right] \\\\\n",
    "& = B_{\\theta}^{2}(\\hat{\\theta}(\\mathbf{X}))+\\operatorname{Var}_{\\theta}(\\hat{\\theta}(\\mathbf{X}))\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "> Notemos que si nuestro estimador es insesgado, el error cuadrático medio es precisamente la varianza del estimador\n",
    "\n",
    "***(Dem 20211117 43:00)***\n",
    "\n",
    "> Notemos que la varianza ($\\operatorname{Var}(\\hat{\\theta})$) es un mecanismo de precisión y el sesgo ($B^2(\\hat{\\theta})$) es un mecanismo de exactitud\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/SBENUdj47MygvP3zjZQ74hnSJT0gcfxulIZNF_nsFWU.original.fullsize.png)\n",
    "\n",
    "[Bias-variance trade-off](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52612a5-763a-4782-bafb-efab74099a36",
   "metadata": {},
   "source": [
    "> No todo es \"color de rosa...\" El MSE es una función del parámetro y como tal, no siempre es fácil determinar cuál es el \"mejor\" estimador. \n",
    "\n",
    "#### Ejemplo: \n",
    "$X_1,X_2,X_3,X_4 \\sim N(\\theta,4)$ y tenemos que $\\hat{\\theta}_1 =2$ (sacado de la manga) y $\\hat{\\theta}_{MLE}=\\overline{X}_4$  entonces veamos que es mejor. \n",
    "\n",
    "Por un lado $\\hat{\\theta}_1=2$ entonces \n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\hat{\\theta}_1) = \\operatorname{Var}(\\hat{\\theta}_1) + B^2(\\hat{\\theta}_1)\n",
    "$$ \n",
    "\n",
    "entonces al ser una variable aleatoria constante tenemos qur $\\operatorname{Var}(\\hat{\\theta}_1) =\\operatorname{Var}(2) = 0$ (muy preciso) . Ahora $B^2(\\hat{\\theta}_1) = E(\\hat{\\theta}_1)-\\theta=2-\\theta$ (es sesgado siempre que $\\theta \\neq 2$). De este modo \n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\hat{\\theta}_1) = \\operatorname{Var}(\\hat{\\theta}_1) + B^2(\\hat{\\theta}_1) = 0 +(2-\\theta)^2 = (2-\\theta)^2\n",
    "$$\n",
    "\n",
    "Por otro lado $\\hat{\\theta}_2 = \\overline{X}_4$ entonces\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\hat{\\theta}_2) = \\operatorname{Var}(\\hat{\\theta}_2) + B^2(\\hat{\\theta}_2)\n",
    "$$ \n",
    "\n",
    "tenemos que $E(\\hat{\\theta}_2)=\\theta$ y por tanto $B^2(\\hat{\\theta}_2) = E(\\hat{\\theta}_2) - \\theta = 0 \\quad \\forall \\theta$ (insesgado), además $\\operatorname{Var}(\\hat{\\theta}_2) = \\frac{\\sigma^2}{n} = \\frac{4}{4} = 1$. De este modo \n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\hat{\\theta}_2) = \\operatorname{Var}(\\hat{\\theta}_2) + B^2(\\hat{\\theta}_2) = 1 + 0 = 1 \n",
    "$$\n",
    "\n",
    "Por lo tanto haciendo la gráfica de los errores cuadráticos medios en función de el valor del parámetro tenemos que\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/kxELvUWfPyNCXGKqoT6pLB787mooV0BwMY3hUahksQk.original.fullsize.png)\n",
    "\n",
    "> Notemos que si $\\operatorname{MSE}(\\hat{\\theta}_1,\\theta) \\leq \\operatorname{MSE}(\\hat{\\theta}_2,\\theta)$ para todo $\\theta \\in \\Theta$ se dice que $\\hat{\\theta}_1$ domina a  $\\hat{\\theta}_2$.\n",
    "\n",
    "> Podemos decir que para el único caso en el que el estimador $\\hat{\\theta}_1$ domina al estmador $\\hat{\\theta}_2$ es para el caso que el valor real del parámetro este lo suficientemente cercano a 2 en no mas de 1 desviación estandar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359155e7-0e29-4bd2-949d-0dc1311df919",
   "metadata": {},
   "source": [
    "### Estrategias para evaluar estimadores\n",
    "\n",
    "- Las constantes siempre serán los mejroes estimadores en un intervalo alrededor de sí, pero en la práctica corresponerían a \"adivinar\" el valor del parámetro sin datos; así que no se consideran buenos estimadores.\n",
    "\n",
    "- **Primera estrategia:** Dado un par de estimadores, decidir cuál de ellos es el \"mejor\" en términos de MSE.\n",
    "\n",
    "- **Segunda estrategia:** Restringirse a una clase particular de estimadores y dentro de ellos tratar de encontrar el mejor.\n",
    "\n",
    "- OJO! No hay que perder de vista que el objetivo es el menor MSE. A veces un estimador con un poco de sesgo tiene un MSE menor que un estimador sin sesgo (*bias-variance trade-off*).\n",
    "\n",
    "> De este modo vemos que es mejor restringirnos a estimadores que tengan sesgo cero y vemos los que tienen la menor varianza. Por lo general es una \"camisa de fuerza\" este criterio, pero pueden existir los casos donde no y siempre se deberian tener presentes los dos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f07af4-9017-4c06-b1e2-c80e4611a7e1",
   "metadata": {},
   "source": [
    "## **Evaluación de estimadores en una** ***muestra finita ($\\forall n, \\ n \\in \\mathbb{N}$)***\n",
    "\n",
    "### **Primera Estrategia: Eficiencia relativa**\n",
    "Dados dos estimadores, $\\hat{\\theta}_1(\\mathbf{X})$ y $\\hat{\\theta}_2(\\mathbf{X})$, para el parámetro $\\theta$; se define como indicador de eficiencia relativa al cociente:\n",
    "\n",
    "$$\n",
    "R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) \\doteq \\frac{\\operatorname{MSE}\\left(\\hat{\\theta}_{1}(\\mathbf{X}), \\theta\\right)}{\\operatorname{MSE}\\left(\\hat{\\theta}_{2}(\\mathbf{X}), \\theta\\right)}\n",
    "$$\n",
    "\n",
    "- Si $R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) > 1$ entonces $\\hat{\\theta}_{2}$ es más eficiente que $\\hat{\\theta}_{1}$.\n",
    "\n",
    "- Si $R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) < 1$ entonces $\\hat{\\theta}_{1}$ es más eficiente que $\\hat{\\theta}_{2}$.\n",
    "\n",
    "- Si $R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) = 1$ entonces ambos estimadores son igual de eficientes.\n",
    "\n",
    "> Notemos que si los estimadores no tienen sesgo entonces $R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) \\doteq \\frac{\\operatorname{Var}\\left(\\hat{\\theta}_{1}(\\mathbf{X})\\right)}{\\operatorname{Var}\\left(\\hat{\\theta}_{2}(\\mathbf{X})\\right)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fcc71-1713-4dae-8b6f-c72d30c44444",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ejemplo\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad de probabilidad [como en el ejemplo de estimador](NotasDeClase2_DistribucionesMuestrales.ipynb/#EjemploEstimador1) \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_X(x;\\theta) \n",
    "& = \\frac{1}{\\theta}I_{(0,\\theta)} (x) \\\\\n",
    "& = \\begin{cases}\n",
    "        \\frac{1}{\\theta} & \\text{Si } x \\in (0,\\theta) \\\\\n",
    "        0 & \\text{e.o.c} \\\\\n",
    "    \\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "es decir que $X_i \\sim U[0,\\theta]$. Donde vimos que $\\hat{\\theta}_{\\text {MOM }}=2 \\bar{X}_{n}$ y que $\\hat{\\theta}_{\\text {MLE }}=X^{(n)}$ entonces\n",
    "\n",
    "a) Para ver que si ambos estimadores son insesgados tenemos que ver que $B_{\\theta}(\\hat{\\theta}(\\mathbf{X})) \\doteq E[\\hat{\\theta}(\\mathbf{X})]-\\theta=0$ de este modo tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "B_{\\theta}(\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X})) \n",
    "& \\doteq E[\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X})]-\\theta \\\\\n",
    "& = E(2\\overline{X}_n) - \\theta \\\\\n",
    "& = 2E(\\overline{X}_n) - \\theta \\\\\n",
    "& = 2\\frac{0+\\theta}{2} - \\theta \\\\\n",
    "& = \\theta - \\theta \\\\\n",
    "& = 0 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por otro lado tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "B_{\\theta}(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X})) \n",
    "& \\doteq E[\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X})]-\\theta \\\\\n",
    "& = E(X^{(n)}) - \\theta\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Recordando que la [distribución de las estadísticas de orden](NotasDeClase2_DistribucionesMuestrales.ipynb/#TeoremaDistribucionEstadisticasOrden) tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "F_{X^{k}} \n",
    "& = \\sum_{j=k}^{n} \\binom{n}{j}[F_X(x)]^j[1-F_x(x)]^{n-j} \\quad , \\quad \\forall x \\in D_X \\\\\n",
    "& = \\sum_{j=n}^{n} \\binom{n}{j}[F_X(x)]^j[1-F_x(x)]^{n-j} \\\\\n",
    "& = \\binom{n}{n}[F_X(x)]^n[1-F_x(x)]^{n-n} \\\\\n",
    "& = [F_X(x)]^n \\\\\n",
    "& =  \\begin{cases}\n",
    "        0^n&{\\text{for }}x<a\\\\\n",
    "        \\left(\\frac {x-a}{b-a}\\right)^n&{\\text{for }}x\\in [a,b]\\\\\n",
    "        1^n&{\\text{for }}x>b\n",
    "     \\end{cases}\\\\\n",
    "& =  \\begin{cases}\n",
    "        0&{\\text{for }}x<0\\\\\n",
    "        \\left(\\frac {x-0}{\\theta-0}\\right)^n&{\\text{for }}x\\in [0,\\theta]\\\\\n",
    "        1&{\\text{for }}x>b\n",
    "     \\end{cases} \\\\\n",
    "F_{X^{(n)}}& =  \\begin{cases}\n",
    "        0&{\\text{for }}x<a\\\\\n",
    "        \\frac {x^n}{\\theta^n}&{\\text{for }}x\\in [0,\\theta]\\\\\n",
    "        1&{\\text{for }}x>b\n",
    "     \\end{cases}\n",
    "\\end{split} \n",
    "$$\n",
    "\n",
    "donde tenemos que $f_{X^{(n)}}(x) = n \\frac{x^{n-1}}{\\theta^n} I_{[0,\\theta]}(x)$ y por tanto \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E(X^{(n)}) \n",
    "& = \\int_{0}^{\\theta}f_{X^{(n)}}(x) dx \\\\\n",
    "& = \\frac{n}{\\theta^n} \\int_{0}^{\\theta}x ^{n}  dx \\\\\n",
    "& = \\frac{n}{\\theta^n} \\frac{\\theta^{n+1}}{n+1} \\Big|_0^{\\theta} \\\\\n",
    "& = \\frac{n}{\\theta^n} \\frac{\\theta^{n+1}}{n+1} \\\\\n",
    "& = \\frac{n}{n+1}\\theta \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y por tanto $B_{\\theta}(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X})) = E(X^{(n)}) - \\theta = \\frac{n}{n+1}\\theta - \\theta = \\frac{-\\theta}{n+1}$ luego el estimado por MLE de la función de distribución es sesgado.\n",
    "\n",
    "> Notemos que el signo del sesgo del estimador por MLE de la muestra aleatoria, al ser negativo nos dice que las estimaciones del valor del parámetro siempre son más pequeñas que el valor real. Tambien es importante ver que a medida que $n \\to \\infty$ tenemos que el sesgo del estimador tiende a cero; esto lo vamos a conocer más adelante como estimador insesgado asintóticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c38eab-c85e-49d6-ad91-45dee560e421",
   "metadata": {},
   "source": [
    "b) Para saber si podemos corregir aquellos que son sesgados notemos que para $\\hat{\\theta}_{\\text{MLE}} = X^{(n)}$ tenemos que $E(X^{(n)}) = \\frac{n}{n+1}\\theta$ de este modo si queremos que $B_{\\theta}(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X}) = E(X^{(n)})-\\theta = 0$ entonces tendríamos que tener que $\\frac{n+1}{n}E(X^{(n)})$ y de este modo $\\hat{\\theta}_{MLE fix} = \\frac{n+1}{n}\\hat{\\theta}_{MLE} = \\frac{n+1}{n}X^{(n)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d0680c-6835-422b-a237-c2a2715f2a49",
   "metadata": {},
   "source": [
    "c) Por último para saber cual de todos estos estimadores tiene menor MSE veamos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{MSE}(\\hat{\\theta}_{\\text{MOM}}, \\theta) \n",
    "& = E_{\\theta}\\left[(\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X})-\\theta)^{2}\\right] \\\\\n",
    "& = B_{\\theta}^{2}(\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X}))+\\operatorname{Var}_{\\theta}(\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X})) \\\\\n",
    "& = \\operatorname{Var}_{\\theta}(\\hat{\\theta}_{\\text{MOM}}(\\mathbf{X})) \\\\\n",
    "& = \\operatorname{Var}_{\\theta}( 2\\overline{X}_n ) \\\\\n",
    "& = 4\\operatorname{Var}_{\\theta}( \\overline{X}_n ) \\\\\n",
    "& = 4\\frac{\\frac{1}{12}(\\theta+0)^2}{n} \\\\\n",
    "& = \\frac{1}{3n}\\theta^2 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Tambien \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{MSE}(\\hat{\\theta}_{\\text{MLE}}, \\theta) \n",
    "& = E_{\\theta}\\left[(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X})-\\theta)^{2}\\right] \\\\\n",
    "& = B_{\\theta}^{2}(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X}))+\\operatorname{Var}_{\\theta}(\\hat{\\theta}_{\\text{MLE}}(\\mathbf{X})) \\\\\n",
    "& = \\frac{\\theta^2}{(n+1)^2} + \\operatorname{Var}_{\\theta}(X^{(n)}) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "donde teniendo en cuenta que $\\operatorname{Var}_{\\theta}(X^{(n)}) = E([X^{(n)}]^2) - [E(X^{(n)})]^2$ y que $E([X^{(n)}]^2)=\\frac{n\\theta^2}{n+2}$ tenemos que  $\\operatorname{MSE}(\\hat{\\theta}_{\\text{MLE}}, \\theta) = \\frac{2\\theta^2}{(n+1)(n+2)}$\n",
    "\n",
    "Y realizando el mismo proceso tenemos que $\\operatorname{MSE fix}(\\hat{\\theta}_{\\text{MLE fix}}, \\theta) = \\frac{\\theta^2}{n(n+2)}$\n",
    "\n",
    "Donde tenemos que $\\hat{\\theta}_{\\text{MLE fix}}$ es el más eficiente de los tre ***(detalles 20211117 1:45:00)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766c54c-3a3c-4a7e-aa6e-3b30f4231a80",
   "metadata": {},
   "source": [
    "### **Segunda estrategia; Búsqueda amplia de los estimadores insesgados**\n",
    "- Al concentrarnos únicamente en los estimaores insesgados de un cierto parámetro, quitamos de la ecuación el término de sesgo y nos enfocamos únicamente en la varianza.\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\hat{\\theta},\\theta)= B_{\\theta}^2(\\hat{\\theta}) + \\operatorname{Var}_{\\theta}(\\hat{\\theta}) = \\operatorname{Var}_{\\theta}(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "- El \"mejor\" estimador dentro de la clase de los estimadores insesgados será entonces el que tenga la varianza más pequeña.\n",
    "    - ¿Podrá esa varianza ser cero? Rta: Dado que eso equivaldría a saber el valor exácto del parámetro vamos a dar por sentado que no es posible una varianza cero y un insesgamiento de cero.\n",
    "    - Si no, ¿hay una cota inferior (*cota de Cramer-Rao*) sobre el valor más pequeño de varianza?\n",
    "    - ¿Habrá un estimador cuya varianza llege a esa cota?\n",
    "   \n",
    "> Note que dado que no podemos encontrar al mejor estimador, dado que las constantes localmente son mas eficientes si podemos considerar a una familia de estimadores que cumplen una característica deseada (el valor esperado del estimador es el parámetro i.e. sin sesgo, la menor varianza > 0 (no constantes))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1b6c8-0352-4d7d-89db-3c35e2b76692",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Evaluación de estimadores en muestra finita: Suficiencia**\n",
    "\n",
    "#### **Suficiencia**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$. $\\mathbf{T}(X_1,X_2,\\cdots,X_n) =: \\mathbf{T}(\\mathbf{X})$ se denomina vector de **estadísticas suficientes** de $\\vec{\\theta}$ si la distribución condicional $X_1,X_2,\\cdots,X_n|\\mathbf{T}=\\mathbf{t}$ no depende de $\\vec{\\theta}$.\n",
    "\n",
    "- Una estadística suficiente resume/recoge toda la información del vector de parámetro de un modelo. Es decir que cuando yo tomo datos, esos datos me están aportando información sobre los parámetros y yo puedo resumir/recoger toda esa información de la muestra en una estadística. Luego cuando condiciono mi muestra a la estadística suficiente dada por el vector $\\mathbf{T}$ ,$\\theta$ ya no juega ningún rol en mi modelo dado que $\\mathbf{T}$ tiene toda la información de $\\theta$\n",
    "\n",
    "- Sin embargo, trabajar con esta definición es bastante engorroso dado que estamos sujetos a si encontramos una estadística que al condicionarla sobre los valores de la muestra, ésta ya no dependa de $\\theta$, ésta estadística es suficiente.\n",
    "\n",
    "- Las [estadísticas](NotasDeClase2_DistribucionesMuestrales.ipynb/#DefinicionEstadistica) suficientes no son necesariamente un [estimador](NotasDeClase2_DistribucionesMuestrales.ipynb/#DefinicionEstimadorPuntual) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279fba6-f077-49e0-8946-cb2a45d7c0d4",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "Sea $X_1,X_2$ una muestra aleatoria $Ber(\\theta)$ donde $\\theta \\in \\Theta = (0,1)$. Para verificar que la estadística $T=X_1+X_2$ es suficiente para $\\theta$ primero recordemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{\\theta}_{\\text{MLE}} = \\hat{\\theta}_{\\text{MOM}} = \\overline{X}_n = \\frac{X_1 + X_2}{2}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "pero lo que queremos ver es que $T=X_1+X_2$ es suficiente. Primero tenemos que encontrar la distribucion de $T$, pero dado que la suma de variables aleatorias con distribución Bernulli es Binomial tenemos que $T \\sim Bin(2,\\theta)$. \n",
    "\n",
    "Supongamos que para este caso no conocemos la distribución de la suma de distribuciones de tipo Bernulli. Primero veamos que el soporte de la variable aleatoria es $D_T=\\{ 0,1,2 \\}$, de este modo tenemos que\n",
    "\n",
    "$$\n",
    "P(T=t) = \n",
    "\\begin{cases}\n",
    "    P(X_1=1,X_2=1)\\overset{\\text{m.a.}}{=} P(X_1=1)P(X_2=1)=\\theta^2 & t=2 \\\\\n",
    "    P(X_1=1,X_2=0 \\ \\lor \\ X_1=0,X_2=1)\\overset{\\text{m.a.}}{=} P(X_1=1)P(X_2=0) + P(X_1=0)P(X_2=1 = 2\\theta(1-\\theta) & t=1 \\\\\n",
    "    P(X_1=0,X_2=0)\\overset{\\text{m.a.}}{=} P(X_1=0)P(X_2=0)=(1-\\theta)^2& t=0 \\\\\n",
    "    0 & \\text{e.o.c.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Ahora tenemos que verificar que $T$ es suficiente si y sólo si $P(X_1=x_1 ,X_2=x_2 | T=t)$ ***no*** depende de $\\theta$ de este modo haciendo uso de la definición de la propiedad condicional.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(X_1=x_1 ,X_2=x_2 | T=t) \n",
    "& = \\frac{P(X_1=x_1 ,X_2=x_2,T=t)}{P(T=t)} \\quad \\text{siempre que } P(T=t)>0 \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "consideremos ahora que $x_1,x_2 \\in \\{ 0,1 \\}$ y $t \\in \\{ 0,1,2 \\}$. Donde tenemos que los diferentes casos\n",
    "\n",
    "- Caso 1 $x_1=x_2=1$ y $t=2$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(X_1=1 ,X_2=1 | T=2) \n",
    "& = \\frac{P(X_1=1 ,X_2=1,T=2)}{P(T=2)} \\\\\n",
    "& = \\frac{P(X_1=1 ,X_2=1,T=2)}{P(T=2)}\\frac{P(X_1=1 ,X_2=1)}{P(X_1=1 ,X_2=1)} \\\\\n",
    "& = \\frac{P(X_1=1 ,X_2=1,T=2)}{P(X_1=1 ,X_2=1)}\\frac{P(X_1=1 ,X_2=1)}{P(T=2)} \\\\\n",
    "& = P(T=2|X_1=1 ,X_2=1)\\frac{P(X_1=1)P(X_2=1)}{P(T=2)} \\\\\n",
    "& = 1\\frac{\\theta^2}{\\theta^2} \\\\\n",
    "& = 1\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "tambien podriamos ver directamente que como el unico caso para el que $T=2$ es \n",
    "![](https://cdn.mathpix.com/snip/images/I0or6gUMRvSpiraGOvik42aGEmCUAdiCYS3TFiec6hc.original.fullsize.png)\n",
    "\n",
    "tenemos que \n",
    "$$\n",
    "\\frac{P(X_1=1 ,X_2=1,T=2)}{P(T=2)} = \\frac{P(X_1=1 ,X_2=1)}{P(T=2)} = 1\n",
    "$$\n",
    "\n",
    "- Caso 2 $x_1=x_2=0$ y $t=0$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(X_1=0 ,X_2=0 | T=0) \n",
    "& = \\frac{P(X_1=0 ,X_2=0,T=0)}{P(T=0)} \\\\\n",
    "& = \\frac{P(X_1=0 ,X_2=0,T=0)}{P(T=0)}\\frac{P(X_1=0 ,X_2=0)}{P(X_1=0 ,X_2=0} \\\\\n",
    "& = \\frac{P(X_1=0 ,X_2=0,T=0)}{P(X_1=0 ,X_2=0)}\\frac{P(X_1=0 ,X_2=0)}{P(T=0)} \\\\\n",
    "& = P(T=0|X_1=0 ,X_2=0)\\frac{P(X_1=0)P(X_2=0)}{P(T=0)} \\\\\n",
    "& = 1\\frac{(1-\\theta)^2}{(1-\\theta)^2} \\\\\n",
    "& = 1\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- Caso 3 $x_1=1,x_2=0$ y $t=1$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(X_1=1 ,X_2=0 | T=1) \n",
    "& = \\frac{P(X_1=1 ,X_2=0,T=1)}{P(T=1)} \\\\\n",
    "& = \\frac{P(X_1=1 ,X_2=0,T=1)}{P(T=1)}\\frac{P(X_1=1 ,X_2=0)}{P(X_1=1 ,X_2=0} \\\\\n",
    "& = \\frac{P(X_1=1 ,X_2=0,T=1)}{P(X_1=1 ,X_2=0)}\\frac{P(X_1=1 ,X_2=0)}{P(T=1)} \\\\\n",
    "& = P(T=1|X_1=1 ,X_2=0)\\frac{P(X_1=1)P(X_2=0)}{P(T=1)} \\\\\n",
    "& = 1\\frac{\\theta(1-\\theta)}{2\\theta(1-\\theta)} \\\\\n",
    "& = \\frac{1}{2}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "- Caso 4 $x_1=0,x_2=1$ y $t=1$ es análogo al caso 3.\n",
    "\n",
    "Teniendo en cuenta que el resto de casos son cero tenemos que  \n",
    "\n",
    "$$\n",
    "P(X_1=x_1 ,X_2=x_2 | T=t) =\n",
    "\\begin{cases}\n",
    "    1 & (x_1=x_2=1 , t=2) \\lor (x_1=x_2=0 , t=0) \\\\\n",
    "    \\frac{1}{2} & (x_1=1,x_2=0 , t=1) \\lor (x_1=0,x_2=1 , t=1) \\\\\n",
    "    0 & \\text{e.o.c.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "> Tengamos en cuenta que la probabilidad condicional es una medida de probabilidad siempre que se fije a t\n",
    "\n",
    "Dado que vimos que $T$ no depende de $\\theta$ tenemos que $T=X_1+X_2$ es una estadística suficiente para $\\theta$\n",
    "\n",
    "> Verificamos que el teorema nos caracteriza las estadísticas suficientes mas no tenemos que de momento sacarlas de la manga y evaluar si en efecto son estadísticas suficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142e22c-9049-4303-8a3c-79ceffc40561",
   "metadata": {},
   "source": [
    "### **Teorema Criterio de factorización de Fisher-Neyman**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$. \n",
    "\n",
    "Las estadísticas $T_1(\\mathbf{X}),T_2(\\mathbf{X}),\\cdots,T_m(\\mathbf{X})$ constituyen una colección de **estadísticas conjuntamente suficientes** para $\\vec{\\theta}$ si y sólo si \n",
    "\n",
    "$$\n",
    "L(\\vec{\\theta}|\\mathbf{x}) = g(t_1(\\mathbf{x}),t_2(\\mathbf{x}),\\cdots,t_m(\\mathbf{x});\\vec{\\theta})h(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "con ambas funciones no negativas.\n",
    "\n",
    "- Las estadísticas fucientes no se definen de manera única. Cualquier función 1-1 de un vector de estadísticas suficientes sigue siendo suficiente.\n",
    "\n",
    "> Notemos que para nuestro ejemplo anterior $T_2=4(X_1+X_2)$ o $T_3=X_1+X_2+3$ tambien son unas estadísticas sufientes para $\\theta$ donde $X_1,X_2$ muestra aleatorioa donde $X_1,X_2 \\sim Ber(\\theta)$.\n",
    "\n",
    "***(Dem 1:08:00 20211122)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d822fa-3312-40c8-9ffd-3bbc6e48214d",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aletoria $Ber(\\theta)$. En el [ejemplo](NotasDeClase2_DistribucionesMuestrales.ipynb/#EjemploMLEBer) donde estudiabamos las el estimador por verosimilitud de $\\theta$ de una muestra aleatoria con función de distribución de tipo Bernulli la función de verosimilitud del parametro era\n",
    "\n",
    "$$\n",
    "L(\\theta,\\mathbf{x}) =\n",
    "\\begin{cases} \n",
    "        \\theta^n & \\theta=1 \\\\\n",
    "        \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\prod_{i=1}^{n} I_{\\{0,1\\}}(x_i)  & 0<\\theta<1\\\\\n",
    "        (1-\\theta)^n & \\theta=0 \\\\\n",
    "        0 & \\text{en otro caso}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Donde al excluir casos degenerados, es decir tomando a $\\theta \\in (0,1)$ tenemos que\n",
    "\n",
    "$$\n",
    "L(\\theta,\\mathbf{x}) = \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\prod_{i=1}^{n} I_{\\{0,1\\}}(x_i)  \n",
    "$$\n",
    "\n",
    "Así dejando a $g(\\vec{t},\\theta)= \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } $ y $h(\\mathbf{x}) = \\prod_{i=1}^{n} I_{\\{0,1\\}}(x_i)$ tenemos que las estadísticas suficientes para el parámetro $\\theta$ son $\\sum_{i=1}^{n} x_i$ tambien $(\\sum_{i=1}^{n} x_i, n-\\sum_{i=1}^{n} x_i)$ tambien $(X_1,X_2,\\cdots,X_n)$ tambien ...\n",
    "\n",
    "> Notemos $(X_1,X_2,\\cdots,X_n)$ es un estadística suficiente dado que si tenemos que $X_1,X_2,\\cdots,X_n|X_1=x_1,X_2=x_2,\\cdots,X_n=x_n$ no es aleatorio y por tanto no depende de $\\theta$\n",
    "\n",
    "> Notemos tambien que las estadísticas suficientes que nos interezan mas son aquellos vectores de menor dimensión, dado que para el caso son aquellas que retienen información del parámetro de manera más sintética. Esto se verificará mas adelante en eficiencia de estadísticas suficientes. Para este caso las que sacamos de menor  dimensión pueden ser $\\sum_{i=1}^{n} x_i$, $n - \\sum_{i=1}^{n} x_i$ e incluso $\\overline{X}_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3a102-14c5-4a78-9ee3-264c260feb8a",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con distribución $N(\\mu,\\sigma^2)$. Tomando a $\\vec{\\theta} = (\\mu,\\sigma^2)^T$ para encontrar una o varias estadísticas sufientes para $\\vec{\\theta}$ tenemos dado el [ejemplo](#EjemploMLEExponencialNormal) visto al estudiar las familias exponenciales que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\mathbf{x}|\\vec{\\theta}) \n",
    "& = \\frac{1}{(\\sigma\\sqrt{2\\pi})^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2\\right] \\\\\n",
    "& = \\frac{1}{(2\\pi)^{\\frac{n}{2}}} \\frac{1}{(\\sigma)^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2\\right] \\\\\n",
    "& = \\frac{1}{(2\\pi)^{\\frac{n}{2}}} \\frac{1}{(\\sigma)^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\left( \\sum_{i=1}^{n} x_i^2 -2\\mu\\sum_{i=1}^{n} x_i + n\\mu^2 \\right) \\right] \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "De este podriamos escoger que $g(\\vec{t},\\theta)=\\frac{1}{(\\sigma)^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\left( \\sum_{i=1}^{n} x_i^2 -2\\mu\\sum_{i=1}^{n} x_i + n\\mu^2 \\right) \\right] $ y $h(\\mathbf{x})=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}$ y de este modo tendriamos que $\\vec{t}=(\\sum_{i=1}^{n} x_i^2,\\sum_{i=1}^{n} x_i)$\n",
    "\n",
    "> Notemos que no podemos obtener un vector el cual tenga una dimensión menor a dos y esto está asociado al hecho de que nuestro vector $\\vec{\\theta}$ tiene dos parámetros, luego de momento es plausible deducir que en una dimension no podríamos recoger toda la información de los dos parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e09d0-fe7b-4675-be6e-ce79228b6da9",
   "metadata": {},
   "source": [
    "### **Terorema**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ un muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$.\n",
    "\n",
    "Si $\\vec{\\theta}_{\\text{MLE}}$ existe y es único, entonces es función de estadísticas suficientes.\n",
    "\n",
    "> El transfondo de este teorema nos dice que como la idea de la función de verosimilitud es encontral el argumento que maximiza la posibilidad de volver a obtener los mismos datos observados, entonces por el teorema de Fisher Neyman tendría que al $h(\\mathbf{x})$ no depender de $\\theta$ el criterio a maximizar seria simplemente $g(\\mathbf{T},\\vec{\\theta})$ donde tendríamos que llegar a algo como $\\vec{\\theta}_{\\text{MLE}}=f(\\mathbf{T})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e3761-06ce-4e14-a652-044ca8877ca1",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Para verificar el teorema anterior en una muestra aleatoria $X_1,X_2,\\cdots,X_n$ cuya distribución es $Ber(\\theta)$ recordemos que $\\vec{\\theta}_{\\text{MLE}} = \\overline{X}_n$ y como vimos en los ejemplos anteriores al tener que \n",
    "\n",
    "$$\n",
    "L(\\theta,\\mathbf{x}) = \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\prod_{i=1}^{n} I_{\\{0,1\\}}(x_i)  \n",
    "$$\n",
    "\n",
    "entonces $g(\\vec{t},\\theta)= \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i }$ y $h(\\mathbf{x}) = \\prod_{i=1}^{n} I_{\\{0,1\\}}(x_i)$. Por tanto si \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "g(\\vec{t},\\theta) \n",
    "& = \\theta^{\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\\\\n",
    "& = \\theta^{\\frac{n}{n}\\sum_{i=1}^{n} x_i} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\\\\n",
    "& = \\theta^{n\\overline{X}_n} (1 - \\theta)^{n-\\sum_{i=1}^{n} x_i } \\\\\n",
    "\\end{split}$$\n",
    "\n",
    "y de este modo tenemos que $t(\\mathbf{x}) = \\overline{X}_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d95ee-30d3-4bce-81f5-2ff12fb32791",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Verifiquemos ahora el teorema anterior en una muestra aleatoria $X_1,X_2,\\cdots,X_n$ cuya distribución es $N(\\mu,\\sigma^2)$ recordemos que $\\hat{\\mu}_{\\text{MLE}} = \\overline{X}_n$ y $\\hat{\\sigma}^2_{\\text{MLE}} = \\frac{1}{n} \\sum_{i=1}^{n} (X_i + \\overline{X}_n)^2 = \\frac{1}{n} \\sum_{i=1}^{n} X_i^2 - \\overline{X}_n^2$ de este modo tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\mathbf{x}|\\vec{\\theta}) \n",
    "& = \\frac{1}{(2\\pi)^{\\frac{n}{2}}} \\frac{1}{(\\sigma)^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\left( \\sum_{i=1}^{n} x_i^2 -2\\mu\\sum_{i=1}^{n} x_i + n\\mu^2 \\right) \\right] \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "en donde dejando $g(\\vec{t},\\theta)=\\frac{1}{(\\sigma)^n} \\exp\\left[ \\frac{-1}{2\\sigma^2} \\left( \\sum_{i=1}^{n} x_i^2 -2\\mu\\sum_{i=1}^{n} x_i + n\\mu^2 \\right) \\right] $ y $h(\\mathbf{x})=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}$ obtuvimos $\\vec{t}=(\\sum_{i=1}^{n} x_i^2,\\sum_{i=1}^{n} x_i)$ y de este modo tenemos que las estadísticas suficientes dependen de los estimadores por máxima verosimilitud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36540972-64a9-44db-a5bb-37b785a9be58",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "En una distribución uniforme $U(0,\\theta)$ de una muestra aleatoria $X_1,X_2,\\cdots,X_n$ el estimador por máxima verosimilitud entoncontramos que era $\\hat{\\theta}_{\\text{MLE}} = X^{(n)}$ donde recordando el [ejemplo](NotasDeClase2_DistribucionesMuestrales.ipynb/#EjemploEstimador1) vimos que teniamos la siguiente funcion MLE\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta|\\mathbf{x}) \n",
    "& = \\frac{1}{\\theta^n}I_{(X^{(n)},\\infty)}(\\theta) \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "en donde dejando $g(\\vec{t},\\theta)=\\frac{1}{\\theta^n}I_{(X^{(n)}),\\infty}(\\theta)$ y $h(\\mathbf{x})=1$.  Como tenemos entonces que el máximo de la muestra $X^{(n)}$ es tal que es el único térmico que influencia a los datos y por lo tanto la estadísitca suficiente es el máximo de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524615df-c383-4077-a5c6-b8cb9163b8fd",
   "metadata": {},
   "source": [
    "### **Conclusiones**\n",
    "\n",
    "- Las estadísticas suficientes pueden variar en dimensión.\n",
    "\n",
    "- La idea de los principios de reducción de información es almacenar toda la información respecto al vector de parámetros en el objeto de menos dimensión posible, es decir, encontrar la estadística suficiente de menor tamaño.\n",
    "\n",
    "### **Suficiencia minimal**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$. $\\mathbf{T}(X_1,X_2,\\cdots,X_n) =: \\mathbf{\\mathbf{X}}$ se denomina vector de **estadísticas suficientes minimales** si es un vector de estadísticas suficiente y es función de cualquier otra estadítica suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27187b00-3617-4597-b661-25f5b279e052",
   "metadata": {},
   "source": [
    "#### **Teorema**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$.  Si $\\vec{\\hat{\\theta}}_{\\text{MLE}}$ existe y es único, entonces es función de estadísticas suficientes minimales. Si no es único, hay una solición que es función de estadísticas suficientes minimales.\n",
    "\n",
    "#### **Teorema**\n",
    "En la familia exponencial de densidades uniparamétrica, \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} d(X_i)\n",
    "$$ \n",
    "es una estadística suficiente para $\\theta$. En la familia exponencial multiparamétrica, \n",
    "\n",
    "$$\n",
    "\\left(\\sum_{i=1}^{n} d_{1}\\left(X_{i}\\right), \\ldots, \\sum_{i=1}^{n} d_{q}\\left(X_{i}\\right)\\right)^{T}\n",
    "$$\n",
    "es una estadística suficiente para $\\vec{\\theta}$.\n",
    "\n",
    "> Este resultado es sencillo de verificar dado que dada una muestra aleatoria la cual pertenece a la familia exponencial. Tenemos que por la forma de su función verosimilitud $L\\left(\\theta \\mid x_{1}, x_{2}, \\ldots, x_{n}\\right)=a^{n}(\\vec{\\theta})\\left(\\prod_{i=1}^{n} b\\left(x_{i}\\right)\\right) \\exp \\left[\\mathbf{c}(\\vec{\\theta})^{T} \\sum_{i=1}^{n} \\mathbf{d}\\left(x_{i}\\right)\\right]$ tenemos que $h(\\mathbf{x})=\\prod_{i=1}^{n} b\\left(x_{i}\\right)$ y $g(\\vec{\\theta},\\mathbf{x}) = a^{n}(\\vec{\\theta})\\exp \\left[\\mathbf{c}(\\vec{\\theta})^{T} \\sum_{i=1}^{n} \\mathbf{d}\\left(x_{i}\\right)\\right]$ en donde tenemos que en el único lugar donde tenemos dependencia de los datos es en $\\sum_{i=1}^{n} \\mathbf{d}\\left(x_{i}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c0975-1164-44ea-829b-bd366ac871c5",
   "metadata": {},
   "source": [
    "Recordemos unos teoremas de probabilidad\n",
    "### **Teorema ley del valor esperado iterado**\n",
    "Sea $X,Y$ dos variables aleatorias con valores esperados finitos, entoces\n",
    "\n",
    "$$\n",
    "E[X]=E_{Y}\\left[E_{X}[X|Y]\\right]\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "E_{Y}\\left[E_{X}[X \\mid Y]\\right]=E[g(Y)]=\\begin{cases}\n",
    "\\sum_{y \\in D_{Y}} E[X|Y=y] p_{Y}(y), \\text { si } Y \\text { es discreta; } \\\\\n",
    "\\int_{-\\infty}^{\\infty} E[X|Y=y] f_{Y}(y) d y, Y \\text { es continua; }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### **Teorema Ley de la varianza iterada**\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}[X]=\\operatorname{Var}_{Y}\\left[E_{X}[X \\mid Y]\\right]+E_{Y}\\left[\\operatorname{Var}_{X}[X \\mid Y]\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92666a28-0e15-4bc0-9207-1e894b155b19",
   "metadata": {},
   "source": [
    "### **Teorema: Rao-Blackwell**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\theta \\in \\Theta \\mathbb{R}$.\n",
    "\n",
    "Sea $R$ un estimador insesgado de $r(\\theta)$ y sean $T_1,T_2,\\cdots,T_m$ una colección de estadísticas suficientes de $\\theta$. El estimador:\n",
    "\n",
    "$$\n",
    "R_2=E\\left[R|T_1,T_2,\\cdots,T_m\\right]\n",
    "$$\n",
    "\n",
    "1. Es función únicamente de las estadísticas $T_1,T_2,\\cdots,T_m$.\n",
    "2. Es insesgado, es decir, $E[R_2]=r(\\theta)$, para toda $\\theta \\in \\Theta$.\n",
    "3. Tiene menor o igual varianza que $R$, es decir que $\\operatorname{Var}[R_2] \\leq \\operatorname{Var}[R]$ para todo $\\theta \\in \\Theta$.\n",
    "\n",
    "***(Dem 20211124 53:50)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b7b70-d7dd-49bb-89b7-8c9fb27d5b16",
   "metadata": {},
   "source": [
    "<a id='DefinicionInformacionFisher'></a>\n",
    "### **Información de Fisher (para un parámetro constante)**\n",
    "Sea $X$ una variable aleatoria. Se define la información de Fisher como:\n",
    "\n",
    "$$\n",
    "I(\\theta) =\n",
    "\\begin{cases}\n",
    "    E_{\\theta}\\left[\\left( \\frac{\\partial}{\\partial\\theta} \\ln f_X(X,\\theta) \\right)^2\\right], & \\text{si $X$ es continua;}\\\\\n",
    "    E_{\\theta}\\left[\\left( \\frac{\\partial}{\\partial\\theta} \\ln p_X(X,\\theta) \\right)^2\\right], & \\text{si $X$ es discreta;}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "siempre que la derivada exista $\\forall x \\in D_X, \\theta \\in \\Theta \\subseteq \\mathbb{R}$\n",
    "\n",
    "> Notemos que el parámetro en la función de densidad, o en la función de masa es $X$ la cual le da una conotación de variable aleatoria. Este valor esperado nos va a ser útiles.\n",
    "\n",
    "### **Información de Fisher (para un vector de parámetros)**\n",
    "Sea $X$ una variable aleatoria. Se define la información de Fisher como:\n",
    "\n",
    "$$\n",
    "\\mathbf{I}(\\vec{\\theta}) =\n",
    "\\begin{cases}\n",
    "    E_{\\vec{\\theta}}\\left[\\frac{\\partial}{\\partial\\vec{\\theta}} \\ln f_X(X,\\vec{\\theta}) \\left( \\frac{\\partial}{\\partial\\vec{\\theta}} \\ln f_X(X,\\vec{\\theta}) \\right)^T\\right], & \\text{si $X$ es continua;}\\\\\n",
    "    E_{\\vec{\\theta}}\\left[\\frac{\\partial}{\\partial\\vec{\\theta}} \\ln f_X(X,\\vec{\\theta}) \\left( \\frac{\\partial}{\\partial\\vec{\\theta}} \\ln p_X(X,\\vec{\\theta}) \\right)^T\\right], & \\text{si $X$ es discreta;}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "siempre que la derivada exista $\\forall x \\in D_X, \\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ce8de-dbff-4d37-9d2a-dc96c3ffdc4f",
   "metadata": {},
   "source": [
    "<a id='DefinicionCondicionesRegularidad'></a>\n",
    "### **Caso regular de estimación (Condidiones de regularidad)**\n",
    "Se dice que está en un caso regular de estimación cuando:\n",
    "\n",
    "1. $\\frac{\\partial}{\\partial\\theta}\\ln f_(x,\\theta)$ o $\\frac{\\partial}{\\partial\\theta}\\ln p_(x,\\theta)$ existen $\\forall x \\in D_X, \\theta \\in \\Theta$\n",
    "\n",
    "2. $I(\\theta)$ existe y es finita paora todo $\\theta \\in \\Theta$.\n",
    "\n",
    "3. El operador $\\frac{\\partial}{\\partial \\theta}$ puede intercambiarse con el símbolo de integral/suma en el cálculo de valores esperados de las estadísticas de la forma $T(X_1,\\cdots,X_n)$ o constantes.\n",
    "\n",
    "> Nota: En la práctica, se dirá que se tiene un caso regular de estimación cuando $D_X$ no depende de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13347fb-a0ba-4045-9a50-1a2543484c28",
   "metadata": {},
   "source": [
    "#### Información de Fisher en un caso regular de estiamción\n",
    "\n",
    "$$\n",
    "I(\\theta)=\n",
    "\\begin{cases}\n",
    "E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln f_{X}(X, \\theta)\\right], & \\text { si } X \\text { es continua; } \\\\\n",
    "E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln p_{X}(X, \\theta)\\right], & \\text { si } X \\text { es discreta; }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "siempre que la derivada exista $\\forall x \\in D_X$, con $\\theta \\in \\Theta \\subseteq \\mathbb{R}$.\n",
    "\n",
    "> Vemos entonces que para casos regulares la información de Fisher es mas sencilla de calcular dado que siempre podemos derivar una segunda vez y un valor esperado de una variable aleatoria al cuadrado podría ser un proceso mas complicado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acddf6d-cb15-4d9f-97a0-6bbfb8ce3c67",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Para calcular la información de Fisher de una muestra aleatoria $X_1,X_2, \\cdots, X_n$ donde $X_i \\sim U[0,\\theta]$ en principio podemos ver que no tenemos condiciones de regularidad, dado que el soporte de la variable aleatoria depende del parámetro. Esto lo podemos verificar en su función de densidad\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f_X(x;\\theta) \n",
    "& = \\frac{1}{\\theta}I_{(0,\\theta)} (x) \\\\\n",
    "& = \\begin{cases}\n",
    "        \\frac{1}{\\theta} & \\text{Si } x \\in (0,\\theta) \\\\\n",
    "        0 & \\text{e.o.c} \\\\\n",
    "    \\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y efectivamente tenemos que $D_X=[0,\\theta]$. De este modo tenemos que la información de Fisher es\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(\\theta) \n",
    "& = E\\left[\\left( \\frac{\\partial}{\\partial\\theta} \\ln f_X(X,\\theta) \\right)^2\\right] \\\\\n",
    "& = E\\left[\\left( \\frac{\\partial}{\\partial\\theta} \\ln \\frac{1}{\\theta}I_{(0,\\theta)} (X) \\right)^2\\right] \\\\\n",
    "& = E\\left[\\left( \\frac{\\partial}{\\partial\\theta} -\\ln \\theta + \\ln I_{(0,\\theta)} (X) \\right)^2\\right] \\\\\n",
    "& = E\\left[\\left( \\frac{\\partial}{\\partial\\theta} -\\ln \\theta \\right)^2\\right] \\\\\n",
    "& = E\\left[\\left( \\frac{-1}{\\theta }\\right)^2\\right] \\\\\n",
    "& = E\\left[\\frac{1}{\\theta^2}\\right] \\\\\n",
    "& = \\frac{1}{\\theta^2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "> Notemos que la indicadora se va a $1$ dado que tenemos una variable aleatoría la cual siempre va a tomar valores entre $0$ y $\\theta$. Además es importante ver que $\\theta$ sigue siendo una constante, por tanto no es aleatoria y de este modo su valor esperado siempre será esa misma constante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7e114-985b-468e-ba62-8318ff461504",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Para calcular la información de Fisher de una muestra aleatoria $X_1,X_2, \\cdots, X_n$ donde $X_i \\sim N(\\theta,\\sigma^2)$ donde la varianza $\\sigma^2$ es conocida veamos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(x,\\vec{\\theta}) \n",
    "& = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right)^{2} \\right]} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y por tanto tenemos que el soporte del parámetro es $D_X = \\mathbb{R}$ y al no ser dependiente del parámetro tenemos que tiene condiciones de regularidad; entonces para calcular la información de Fisher tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(\\theta) \n",
    "& = E\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln f_{X}(X, \\theta)\\right] \\\\\n",
    "& = E\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp{\\left[ -\\frac{1}{2} \\left( \\frac{X-\\theta}{\\sigma} \\right)^{2} \\right]}\\right] \\\\\n",
    "& = E\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}}\\left( -\\ln \\sigma\\sqrt{2\\pi} + \\left[ -\\frac{1}{2} \\frac{\\left(X-\\theta \\right)^{2}}{\\sigma^2}  \\right]\\right)\\right] \\\\\n",
    "& = E\\left[-\\frac{\\partial}{\\partial \\theta}\\left( \\frac{X-\\theta}{\\sigma^2} \\right) \\right] \\\\\n",
    "& = E\\left[\\frac{1}{\\sigma^2} \\right] \\\\\n",
    "& = \\frac{1}{\\sigma^2} \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10ee298-1dbd-427e-a116-e116d7d1bac6",
   "metadata": {},
   "source": [
    "### **UMVUE (Uniformly Minimum-Variance Unbiased Estimator)**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\theta \\in \\Theta \\subseteq \\mathbb{R}$. Sea $\\overset{\\sim}{\\theta}(\\mathbf{X})$ un estimador insesgado de $r(\\theta)$. Dicho estimador es **insesgado de varianza uniformemente mínima (UMVUE)** si: \n",
    "\n",
    "$$\n",
    "\\operatorname{Var}[\\overset{\\sim}{\\theta}(\\mathbf{X})] \\leq \\operatorname{Var}[\\hat{\\theta}(\\mathbf{X})]\n",
    "$$\n",
    "\n",
    "para todo $\\theta \\in \\Theta$, siendo $\\hat{\\theta}(\\mathbf{X})$ cualquier otro estimador insesgado de $r(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d409e7-5cb7-4fb4-83a6-0335542ae74c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='TeoremaCotaCramerRao'></a>\n",
    "### **Teorema Cota de Cramer Rao**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densida/masa de probabilidad $f_X/P_X$ parametrizada pro $\\theta \\in \\Theta \\subseteq \\mathbb{R}$. Sea $R(\\mathbf{X})$  un estimador de $r(\\theta)$ y $B_{\\theta}(R)$ su sesgo. Entonces, dentro de un caso regular de estimación\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(R, r(\\theta)) \\geq \\frac{\\left(r^{\\prime}(\\theta)+B_{\\theta}^{\\prime}(R)\\right)^{2}}{n I(\\theta)}, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "donde $I(\\theta)$ es la información de Fisher del parámetro $\\theta$.\n",
    "\n",
    "### **Colorario 1**\n",
    "Sea $R(\\mathbf{X})$ un estimador insesgado de $r(\\theta)$. Entonces, dentor de un caso regular de estimación\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}[R(\\mathbf{X})] \\geq \\frac{\\left(r^{\\prime}(\\theta)\\right)^{2}}{n I(\\theta)}, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "### **Colorario 2**\n",
    "Sea $\\hat{\\theta}(\\mathbf{X})$ un estimador insesgado de $\\theta$. Entonces, dentro de un caso regular de estimación\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}[\\hat{\\theta}(\\mathbf{X})] \\geq \\frac{1}{n I(\\theta)}, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "> Notemos que para los casos donde tenemos un estimador insesgado y estamos dentro de un caso regular de estimación entonces la información de la cota se simplifica bastante. De este modo ese valor mas pequeño de la varianza que podemos llegar a obtener en siempre para un caso regular de estimación y se simplifica a medida que tenemos un estimador insesgado.\n",
    "\n",
    "#### Preguntas importantes\n",
    "\n",
    "- ¿Hay estimadores que pueden alcanzar la cota? Si, generalmente dentro de la familia exponencial. A estos estimadores se les llama **Brue: Best Regular Unbiased Estimator.**\n",
    "\n",
    "-Todo BRUE es un UMVUE pero no todo UMVUE es un BRUE.\n",
    "\n",
    "- ¿Hay estimadores que pueden estar por debajo de la cota? Si, cuando no se tiene condiciones de regularidad (En el taller se tienen ejemploss.)\n",
    "\n",
    "> Generalmente alcanzamos un BRUE cuando tenemos casos regulares de estimación i.e. cuando el el soporte de la variable aleatoria $D_X$ no depende del parámetro a estimar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42715cde-991a-4586-a15d-89d0740188ce",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "Para $X_1,X_2,\\cdots,X_n$ una muestra aleatoria $N(\\theta,\\sigma^2)$, $\\sigma^2$ conocido, determine si el MLE de $\\mu$ es un BRUE.\n",
    "\n",
    "Dado que tenemos que el MLE para una normal es $\\hat{\\theta}_{MLE}=\\overline{X}_n$ entonces $\\operatorname{Var}(\\hat{\\theta}_{MLE})=\\operatorname{Var}(\\overline{X}_n)=\\frac{\\sigma^2}{n}$ y teniendo en cuenta que $I(\\theta)=\\frac{1}{\\sigma^2}$. Tenemos que la cota de Cramer-Rao es $\\frac{1}{nI(\\theta)}=\\frac{1}{n\\frac{1}{\\sigma^2}}=\\frac{\\sigma^2}{n}$. Lo que quiere decir que el MLE para una normal donde su varianza es conocida es un BRUE dado que alcanza la cota de Cramer Rao.\n",
    "\n",
    "Tambien tenemos que todo estimador insesgado de $\\mu$ tiene una varianza mayor o igual a $\\frac{\\sigma^2}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb840d-0aa7-46ba-9548-9db7ae1bc47c",
   "metadata": {},
   "source": [
    "### **Completez (No pérdida de información)** \n",
    "La distribución de una variable aleatoria $X$ se dice **completa** si \n",
    "\n",
    "$$\n",
    "E_{\\theta}[z(X)]=0, \\forall \\theta \\in \\Theta \\Leftrightarrow z(X) \\equiv 0 \\quad \\text{c.s.}\n",
    "$$\n",
    "\n",
    "Una estadística se dice completa si su distribución verifica la condición anterior.\n",
    "\n",
    "> La completez se puede asociar con los criterios de independencia lineal vistos en álgebra donde la única solución para que el sistema sea $0$ es que cada valor del vector sea $0$. Y de este modo podemos concluir que tódos los vectores de la base aportan información de la dimensión de la base.\n",
    "\n",
    "<a id='TeoremaCompletezFamiliaExponencial'></a>\n",
    "### **Teorema (La familia exponencial de densidades y la completez)**\n",
    "En la familia exponencial de densidades uniparmétrica, \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} d(X_i)\n",
    "$$ \n",
    "es una estadística suficiente y completa para $\\theta$. \n",
    "\n",
    "En la familia exponencial multiparamétrica, \n",
    "\n",
    "$$\n",
    "\\left(\\sum_{i=1}^{n} d_{1}\\left(X_{i}\\right), \\ldots, \\sum_{i=1}^{n} d_{q}\\left(X_{i}\\right)\\right)^{T}\n",
    "$$\n",
    "\n",
    "es suficiente y completa para $\\vec{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadde5b5-867e-4e14-bc6e-a4258a789765",
   "metadata": {},
   "source": [
    "<a id='TeoremaLehmanScheffe'></a>\n",
    "### **Teorema: Lehman-Scheffé**\n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria con función de densidad/masa de probabilidad $f_X/p_X$ parametrizada por $\\theta \\in \\Theta \\subseteq \\mathbb{R}$.\n",
    "\n",
    "Si $T_1(\\mathbf{X}), T_2(\\mathbf{X}), \\cdots, T_m(\\mathbf{X})$ son estadísticas suficientes y completas de $\\theta$ y $\\hat{\\theta}(\\mathbf{X})$ es un estimador insesgado que es función de $T_1(\\mathbf{X}), T_2(\\mathbf{X}), \\cdots, T_m(\\mathbf{X}), \\hat{\\theta}(\\mathbf{X})$ es un UMVUE.\n",
    "\n",
    "- En conclusión, es necesario construir un estimador insesgado a partir de las estadísticas suficientes y completas para obtener un UMVUE.\n",
    "\n",
    "- Este teorema no garantiza que el UMVUE sea un BRUE, ya que este resultado no está restringido a la familia exponencial.\n",
    "\n",
    "> Notemos que el estimador insesgado tiene que ser función de todas las estadíticas sufientes minimales, para que efectivamente tengamos que el estimador es un UMVUE. La prueba de la existencia y la unicidad está en Mayorga. Entonces en conclusión este teorema nos quiere decir que si tenemos un vector de estadísticas suficientes minimales y completas del parámetro y un estimador que es función de estas estadísticas suficientes, entonces ese estimador es un UMVUE. Dentro del los límites de este curso tenemos unicamente que en las familias exponenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018cb8b-3ac6-4758-917e-173aeedb3152",
   "metadata": {},
   "source": [
    "> Como el teorema de Leheman-Sheffé garantiza la unicidad de UMVUE. ***(20211129 37:00)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f25dc-6210-4388-bda6-79d529e0cc9b",
   "metadata": {},
   "source": [
    "### ¿Como podemos contruir el UMVUE?\n",
    "\n",
    "| Teromea de Rao Blackwell | Teorema de Lehman-Scheffé |\n",
    "|---|---|\n",
    "| Un estimador insesgado  | Estadíticas suficientes y completas |\n",
    "| Estadísticas suficientes y completas | |\n",
    "| $E[R|T_1,\\cdots,T_n]$ | Tratando de combinar a las estadíticias |\n",
    "| (necesario tener un | con el fin de obtener un |\n",
    "| estimador insesgado) | estimador insesgado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03ffad-a1b2-4873-81a9-a88fc5b05b10",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "Sea $X_1, X_2, \\cdots, X_n$ una muestra aleatoria con ditribución $Exp(\\theta)$. Determinar el UMVUE para estimar la tasa promedio por unidad de tiempo de courrencia de fenómenos y el tiempo promedio entre fenómenos.\n",
    "\n",
    "Tenemos que el tiempo promedio entre fenómenos es $E(X)=\\frac{1}{\\theta}$ y por otro lado la tasa pormedio por unidad de tiempo de ocurrencia entre fenómenos es $\\theta$. Dado que tenemos que la función de densidad de una variable aleatoria con distribución exponencial es\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(x;\\theta) \n",
    "& = \\theta e^{-\\theta x } I_{(0,\\infty)}(x) \\\\\n",
    "& = \\theta I_{(0,\\infty)}(x) e^{-\\theta x } \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "tenemos que la pertence a la familia exponencial de densidades. De este modo por el [teorema de la completez en la familia exponencia de densidades](#TeoremaCompletezFamiliaExponencial) tenemos que la **estadística natural** $x=d(x)$ es tal que \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} d(X_i) = \\sum_{i=1}^{n} X_i\n",
    "$$\n",
    "\n",
    "es una estadística suficiente y completa. Teniendo en cuenta que $\\overline{X}_n$ es un estimador insesgado de $\\frac{1}{\\theta}$.\n",
    "\n",
    "Teniendo en cuenta que $\\overline{X}_n=\\frac{1}{n} \\sum_{i=1}^{n} X_i$ es función de la estadística suficiente y completa ($\\sum_{i=1}^{n} X_i$) entonces tenemos por el [teorema de Lehman-Sheffé](#TeoremaLehmanScheffe) que $\\overline{X}_n$ es un UMVUE para $\\frac{1}{\\theta}$\n",
    "\n",
    "Para saber si es un BRUE tenemos que ver que alcanza la [cota de Cramer-Rao](#TeoremaCotaCramerRao), de este modo según el colorario 1 tenemos que para nuestro estimador $\\overline{X}_n$ un estimador insesgado de $\\frac{1}{\\theta}$. Entonces, dentro de un caso regular de estimación\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{Var}[\\overline{X}_n] \\geq \\frac{\\left(\\frac{d}{d\\theta}\\frac{1}{\\theta}\\right)^{2}}{n I(\\theta)}, \\forall \\theta \\in \\Theta\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Donde teniendo en cuenta que $I(\\theta)$ es la [información de fisher](#DefinicionInformacionFisher) del parámetro y teniendo en cuenta que tenemos un caso regular de estimación dado que el soporte de la variable aleatoria $D_X=[0,\\infty)$ no depende del parámetro; entonces \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "I(\\theta) \n",
    "& = E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln f_{X}(X, \\theta)\\right] \\\\\n",
    "& = E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln \\theta I_{(0,\\infty)}(X) e^{-\\theta X } \\right] \\\\\n",
    "& = E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln \\theta e^{-\\theta X } \\right] \\\\\n",
    "& = E_{\\theta}\\left[-\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\left( \\ln \\theta -\\theta X  \\right] \\right) \\\\\n",
    "& = E_{\\theta}\\left[-\\frac{\\partial}{\\partial \\theta} \\left( \\frac{1}{\\theta}  - X  \\right] \\right) \\\\\n",
    "& = E_{\\theta}\\left[- \\left( -\\frac{1}{\\theta^2} \\right) \\right]  \\\\\n",
    "& = E_{\\theta}\\left[\\frac{1}{\\theta^2} \\right]  \\\\\n",
    "& =\\frac{1}{\\theta^2} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "y de este modo tenemos que la cota de Cramer Rao es\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\operatorname{Var}[\\overline{X}_n] \n",
    "& \\geq \\frac{\\left(\\frac{d}{d\\theta}\\frac{1}{\\theta}\\right)^{2}}{n I(\\theta)}, \\forall \\theta \\in \\Theta\\\\\n",
    "& = \\frac{\\left(\\frac{-1}{\\theta^2}\\right)^{2}}{n \\frac{1}{\\theta^2}}\\\\\n",
    "& = \\frac{\\frac{1}{\\theta^4}}{ \\frac{n}{\\theta^2}}\\\\\n",
    "& = \\frac{1}{n\\theta^2}\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Por lo tanto teniendo en cuenta que $\\operatorname{Var}[\\overline{X}_n] = \\frac{\\sigma}{n} = \\frac{1}{n\\theta^2}$ tenemos que el estimador alcanza la cota de Cramer-Rao, es decir es el estimador con menor varianza de todos estimadores insesgados para el parámetro $\\frac{1}{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd3f76-ddd3-4862-9a71-370b9492704c",
   "metadata": {},
   "source": [
    "Ahora tenemos que encontrar un estimador UMVUE para $\\theta$ la tasa promedio por unidad de tiempo de ocurrencia de fenómenos.\n",
    "\n",
    "> Recordemos que ***NO*** podemos decir que $\\theta$ tiene como UMVUE a $\\frac{1}{\\overline{X}_n}$ dado que la invarianza sólo la tenemos para los estimadores por MLE. Además tenemos que $E(X)=\\mu$ implica $E(f(X))=f(\\mu)$ SOLAMENTE cuando f es una función lineal. Otro ejemplo seria que $E(\\frac{X}{Y}) = E(X)E(\\frac{1}{Y})$ SIEMPRE que $X$ e $Y$ sean independientes y porque $f(Y)=\\frac{1}{Y}$ NO es un operador lineal\n",
    "\n",
    "Tenemos que empezar nuevamente. Teniendo en cuenta que es necesario un estimador insesgado para $\\theta$ pensemos por un momento en $\\frac{c}{\\sum_{i=1}^{n}} = \\hat{\\theta}_*$ el cual podemos ver que está en función de estadísticas de las estadísticas suficientes y completas para $\\theta$. Si logramos encontrar un $c$ tal que $\\hat{\\theta}_*$ sea insesgado entonces tendriamos un UMVUE por el [teorema de Lehman-Sheffé](#TeoremaLehmanScheffe).\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[\\hat{\\theta}_{*}\\right] \n",
    "& =E\\left[\\frac{c}{\\sum_{i=1}^{n} x_{i}}\\right] \\\\\n",
    "& =c E \\left[ \\frac{1}{\\sum_{i=1}^{n} x_{i}}\\right] \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Teniendo en cuenta que para una variable aleatoria $X$ con distribución $Exp(\\theta)$, la distribución de la variable aleatoria $T=\\sum_{i=1}^{n} X_i$ tiene distribución $\\Gamma(n,\\theta)$. De este modo tenemos que \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "E\\left[\\frac{1}{T}\\right] &=\\int_{0}^{\\infty} \\frac{1}{t} f_{T}(t) d t \\\\\n",
    "&=\\int_{0}^{\\infty} \\frac{1}{t} \\cdot \\frac{1}{\\Gamma(n)} \\theta^{n} t^{n-1} e^{-\\theta t} d t \\\\\n",
    "&=\\frac{1}{\\Gamma(n)} \\int_{0}^{\\infty} \\theta^{n} t^{n-2} e^{-\\theta t} d t \\\\\n",
    "&=\\frac{1}{\\Gamma(n)} \\int_{0}^{\\infty} \\dot{\\theta}^{n-1} \\frac{u^{n-2}}{\\theta^{n-2}} e^{-u} d u \\\\\n",
    "&=\\frac{\\theta}{\\Gamma(n)} \\int_{0}^{\\infty} u^{n-2} e^{-u} d u \\\\\n",
    "&=\\frac{\\theta}{\\Gamma(n)} \\Gamma(n-1)\\\\\n",
    "&=\\frac{\\theta}{(n-1)!} (n-2)! \\\\\n",
    "&=\\frac{\\theta}{n-1} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Donde tenemos que tener en cuenta que la definición de la función Gamma es $\\Gamma(t)=\\int_0^{\\infty} x^{t-1} e^{-x} d x$ y para valores enteros positivos tenemos que $\\Gamma(n)=(n-1)!$ para todo $n \\in \\mathbb{N}$. Por lo tanto tenemos que $E[\\hat{\\theta}_*]=c\\frac{\\theta}{x-1}$ donde si queremos que sea insesgado tenedríamos que tener que $c=(n-1)$. Y de este modo tenemos que $\\frac{n-1}{\\sum_{i=1}^{n} X_i} = \\hat{\\theta}_*$ es el umvue para $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37397fb-ee8a-45b0-b240-e032a37552cd",
   "metadata": {},
   "source": [
    "### **Evaluación Asintótica de Estimadores**\n",
    "Todo lo que hemos desarrollado es en general para muestras finitas, es decir para un tamaño de muestra tal que $n \\in \\mathbb{N}$. Cuando hablemos de las propiedades asintóticas de estimadores vamos a hablar de las propiedades que tienen cuando $n \\to \\infty$. La motivación para esto es que en ocasiones tendremos modelos demaciado complejos los cuales serán mas sencillos de estimar si se empieza a suponer bajo la convergencia a infinito.\n",
    "\n",
    "### **Insesgamiento asintótico (aumento exactitud)**\n",
    "Un estimador $\\hat{\\theta}(\\mathbf{X}_n)$ para el parámetro $\\theta$ se dice asintóticamente insesgado si:\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} B_{\\theta}\\left(\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right)\\right)=0, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "De manera equivalente si:\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} E_{\\theta}\\left(\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right)\\right)=\\theta, \\forall \\theta \\in \\Theta\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6760940-eb58-4dbd-8fb2-bb318894959e",
   "metadata": {},
   "source": [
    "### **Consistencia (aumento de la precisión)**\n",
    "\n",
    "#### **Consistencia simple**\n",
    "Un estimador $\\hat{\\theta}(\\mathbf{X}_n)$ para el parámetro $\\theta$ se dice consistente simple si:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right) \n",
    "\\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}}\n",
    "\\theta, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "#### **Consistencia en MSE**\n",
    "Un estimador $\\hat{\\theta}(\\mathbf{X}_n)$ para el parámetro $\\theta$ se dice consistente en error cuadrático medio si:\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} \\operatorname{MSE}\\left(\\hat{\\theta}\\left(\\mathbf{X}_{n}\\right), \\theta\\right)=0, \\forall \\theta \\in \\Theta\n",
    "$$\n",
    "\n",
    "#### **Teorema**\n",
    "Todo estimador consistente en MSE es también consistente simple.\n",
    "\n",
    "> Notemos que la definición de consistencia simple es la misma que la de convergencia $\\hat{\\theta}_n \\overset{L2}{\\underset{n \\to \\infty}{\\longrightarrow}} \\theta$, de donde sabemos que implica la convergencia en probabilidad $\\hat{\\theta}_n \\overset{p}{\\underset{n \\to \\infty}{\\longrightarrow}} \\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba900c-2651-4aee-a7ba-b91d5966ed06",
   "metadata": {},
   "source": [
    "### **Eficiencia relativa asintótica**\n",
    "Dados dos estimadores $\\hat{\\theta}_1(\\mathbf{X}_n)$ y $\\hat{\\theta}_2(\\mathbf{X}_n)$, para el parámetro $\\theta$ con distribuciones asintóticas normales, es decir:\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(\\hat{\\theta}_{1}(\\mathbf{X})-\\theta\\right)  \n",
    "\\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}}\n",
    "N\\left(0, \\sigma_{\\theta_1}^{2}\\right)\n",
    "$$\n",
    "\n",
    "y \n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(\\hat{\\theta}_{1}(\\mathbf{X})-\\theta\\right)  \n",
    "\\overset{p}{\\underset{n\\to\\infty}{\\longrightarrow}}\n",
    "N\\left(0, \\sigma_{\\theta_2}^{2}\\right)\n",
    "$$\n",
    "\n",
    "Se define como indicador de eficiencia relativa asintótica al cociente:\n",
    "\n",
    "$$\n",
    "A R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) \\doteq \\frac{\\sigma_{\\theta_1}^{2}}{\\sigma_{\\theta_{2}}^{2}}\n",
    "$$\n",
    "\n",
    "Si $A R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) > 1$ significa que $\\hat{\\theta}_2(\\mathbf{X})$ es más eficiente asintóticamente que $\\hat{\\theta}_1(\\mathbf{X})$.\n",
    "\n",
    "Si $A R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) < 1$ significa que $\\hat{\\theta}_1(\\mathbf{X})$ es más eficiente asintóticamente que $\\hat{\\theta}2\\mathbf{X})$.\n",
    "\n",
    "Si $A R E\\left(\\hat{\\theta}_{1}, \\hat{\\theta}_{2}\\right) = 1$ significa que ambos estimadores son asintóticamente igual de eficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45560d78-bba0-4ebc-97b9-857a0eccb527",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "Sea $X_1,X_2,\\cdots,X_n$ una muestra aleatoria $N(\\mu,\\sigma^2)$. Se sabe que $\\hat{\\mu}_{AN} = M_e$ y que $\\hat{\\mu}_{MLE} = \\overline{X}_n$. ¿Cuál de estos dos estimadores será asintóticamente más eficiente?\n",
    "\n",
    "1. Tenemos que  $\\overline{X} \\to N(\\mu,\\frac{\\sigma^2}{n})$ entonces $\\sqrt{n}\\left(\\overline{X}_{n}-\\mu\\right) \\sim N\\left(0, \\sigma^{2}\\right)$ donde podemos decir que $\\sqrt{n}\\left(\\overline{X}_{n}-\\mu\\right) \\overset{d}{\\underset{n \\to \\infty}{\\longrightarrow}} N\\left(0, \\sigma^{2}\\right)$.\n",
    "\n",
    "2. Ahora $\\sqrt{n}(M_e-\\mu) \\underset{n \\rightarrow \\infty}{\\stackrel{d}{\\longrightarrow}} N\\left(0, \\frac{p(1-p)}{f^{2}(\\mu)}\\right)=N(0,\\frac{\\pi\\sigma^2}{2})$, ([Teorema distribución asintótica de estadíticas de orden](NotasDeClase2_DistribucionesMuestrales.ipynb/#TeoremaDistribucionAsintoticaEstadisticaOrden))\n",
    "\n",
    "De este modo tenemos que De este modo tenemos que $\\operatorname{ARE}\\left(\\bar{X}_{n}, M_{e}\\right)=\\frac{\\sigma^{2}}{\\frac{\\pi \\sigma^2}{2}} = \\frac{2}{\\pi} < 1$.Por lo tanto $\\bar{X}_n$ es asintóticamente más eficiente que $M_e$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601ea23-c585-45ca-a53a-ac97b3975ed2",
   "metadata": {},
   "source": [
    "### **Teorema: Distribución asintótica del MOM**\n",
    "\n",
    "Sea $\\vec{\\hat{\\theta}}_{mom}$ el estimador por el método de los momentos de $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^q$.\n",
    "\n",
    "1. El estimador $\\vec{\\hat{\\theta}}_{mom}$ es consistente simple.\n",
    "\n",
    "Además, si para obtener dicho estimador se usaron los momentos:\n",
    "\n",
    "$$\n",
    "E\\left[X^{k}\\right]=\\mu_{k}=h_{k}(\\vec{\\theta}), k=1,2, \\ldots, q, \\text { sea } \\mathbf{h}(\\vec{\\theta}) \\doteq\\left(h_{1}(\\vec{\\theta}), \\ldots, h_{q}(\\vec{\\theta})\\right)^{T}\n",
    "$$\n",
    "\n",
    "y sea $\\mathbf{H}(\\vec{\\theta}) \\doteq \\frac{\\partial \\mathbf{h}(\\vec{\\theta})}{\\partial\\vec{\\theta}}$, una matriz de rango $q$ para todo $\\vec{\\theta} \\in \\Theta$.\n",
    "\n",
    "Entonces,\n",
    "\n",
    "2. \n",
    "$$\n",
    "\\sqrt{n}\\left[\\vec{\\hat{\\theta}}_{\\text {mom}}(\\mathbf{X})-\\vec{\\theta}\\right] \\stackrel{d}{\\rightarrow} N\\left(0,\\left(\\mathbf{H}^{-1}(\\vec{\\theta})\\right)^{T} \\Sigma \\mathbf{H}^{-1}(\\vec{\\theta})\\right)\n",
    "$$ \n",
    "con $\\Sigma_{ij} = \\mu_{j+k} - \\mu_j\\mu_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66510b-0db1-411b-a285-64c7f2153110",
   "metadata": {},
   "source": [
    "### **Teorema: Distribución asintótica del MLE**\n",
    "Sea $\\vec{\\hat{\\theta}}_{\\text {MLE }}$ el estimador ML de $\\vec{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^{q}$. Bajo [condiciones de regularidad](#DefinicionCondicionesRegularidad),\n",
    "\n",
    "1. El estimador $\\vec{\\hat{\\theta}}_{\\mathrm{MLE}}$ es asintóticamente insesgado.\n",
    "\n",
    "2. El estimador $\\vec{\\hat{\\theta}}_{\\text {MLE }}$ es consistente simple y en MSE.\n",
    "\n",
    "3. $\\sqrt{n}\\left[\\vec{\\hat{\\theta}}_{\\mathrm{MLE}}(\\mathbf{X})-\\vec{\\theta}\\right]\\overset{d}{\\underset{n \\rightarrow \\infty}{\\longrightarrow}} N\\left(0, \\mathbf{I}^{-1}(\\vec{\\theta})\\right)$.\n",
    "\n",
    "4. Es asintóticamente eficiente respecto a casi cualquier otro estimador.\n",
    "\n",
    "> Nota recordemos que $I(\\theta)$ es la información de Fisher. Tambien dada la convergencia, podríamos aproximar $\\hat{\\theta}_{MLE} \\approx N(\\theta,\\frac{1}{nI(\\theta)})$, es decir que en el infiníto alcanza la cota de Cramer-Rao. De este modo tenemos que es asintóticamente eficiente a casi cualquier otro estimador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b24da-5ee0-40fb-9d8c-f962360d0108",
   "metadata": {},
   "source": [
    "## Conclusiones de la estimación puntual\n",
    "En muestra finita vimos que podemos trabajar con los estimadores los cuales osn insesgados, no sin antes definir el error cuadrático medio. Algunos estimadores asintóticamente pueden cumplir estas propiedades y en particular nos podemos concentrar en aquellos estimadores calculados por MLE. Trabajar asintóticamente está motivado dado que muchos problemas los valores esperados de los estimadores no se pueden encontrar analíticamente, luego es normal que computacionalemente mediante simulación se puede permitir encontrar ciertas estimaciones que se adecuen a nuestro parámetro.\n",
    "\n",
    "Es importante segir teniendo en cuenta que el la mayoria de ocaciones el trabajo multidiciplinar no permite que se le explique al grupo toda esta teoría para llegar a explicar el estimador, incluso en muchas ocasiones lo que se espera es que se de una estimación para el parámetro dejando el trabajo teoriórico como una parte \"documental\". De este modo veamos que:\n",
    "\n",
    "![](https://cdn.mathpix.com/snip/images/liQo25-hDepT7iHKSVSm3XI41iqauJc6CI9Qc2A6Rg4.original.fullsize.png)\n",
    "\n",
    "*\"There is no a free lunch\"*\n",
    "\n",
    "Desde la practica tambien muchas veces tenemos que \n",
    "\n",
    "- El insesgamiento es una propiedad esquiva. Mejor mantener una perspectiva más amplia a la hora de buscar estimadores para muchos parámetros en un modelo.\n",
    "\n",
    "- En la práctica profesional, a menos de que se haga investigación en estadística, a la gente no le interesa leer/oír de estimadores, eso es el trabajo del estadístico antes de presentar los resultados. Lo que la gente quiere oír son las estimaciones a la luz de los datos y sus implicaciones en el contexto del problema.\n",
    "\n",
    "- La calidad de las estimaciones no se puede evaluar, solo las de los estimadores, así que es incorrecto decir \"estimación insestgada, estimación consistente,..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a24bc-4e36-4ab5-a525-fa53dcd6cfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
